{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERTClassification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMfU3XkTHiqln6kn03kAHAH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NirantK/Hinglish/blob/BERT/BERTClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eicOvVptEJD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q keras-bert keras-rectified-adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzY5G1OwEgai",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "0fc38803-c958-4559-b795-45a07913adfc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Mv73NIYEzYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "db76d5c4-b1cc-4523-bcc8-54074a3eab90"
      },
      "source": [
        "!cp drive/My\\ Drive/Hinglish/pretrained_bert500k.tar.gz .\n",
        "!mv pretrained_bert500k.tar.gz pretrained_bert.tar.gz\n",
        "!tar -xvf pretrained_bert.tar.gz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pretrained_bert/\n",
            "pretrained_bert/bert_model.ckpt.data-00000-of-00001\n",
            "pretrained_bert/bert_config.json\n",
            "pretrained_bert/bert_model.ckpt.meta\n",
            "pretrained_bert/vocab.txt\n",
            "pretrained_bert/bert_model.ckpt.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k65lo4JmFTPD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "292f8fd1-fa78-4465-e7fb-c424279f9fc8"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "def clean(df):\n",
        "    df[\"clean_text\"] = df[\"text\"]\n",
        "    df[\"clean_text\"] = (\n",
        "        (df[\"clean_text\"])\n",
        "            .apply(lambda text: re.sub(r\"RT\\s@\\w+\", \"\", text)) #Removes RTS\n",
        "            .apply(lambda text: re.sub(r\"@\", \"mention\", text)) # Replaces @ with mention\n",
        "            .apply(lambda text: re.sub(r\"#\", \"hashtag\", text)) # Replaces # with hastag\n",
        "            .apply(lambda text: re.sub(r\"http\\S+\", \"\", text)) # Removes URL\n",
        "        )\n",
        "    return df\n",
        "# train and test json are available here https://drive.google.com/open?id=1Ij_THj01L-2Y1a8woOn9vXmHosW83e3R\n",
        "# They are labeled twitter jsons with sentiments [\"positive\", \"negative\", \"neutral\"] attached to them\n",
        "traindf= pd.read_json(\"drive/My Drive/Hinglish/interim/train.json\")\n",
        "testdf= pd.read_json(\"drive/My Drive/Hinglish/interim/test.json\")\n",
        "\n",
        "traindf = clean(traindf)\n",
        "testdf = clean(testdf)\n",
        "len(traindf), len(testdf)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13600, 3400)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjSfKhTMFeqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(traindf['sentiment'])\n",
        "traindf['label'] = le.transform(traindf['sentiment'])\n",
        "testdf['label'] = le.transform(testdf['sentiment'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DIxivEmHKij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "4aed119b-ab58-439e-aa92-12c9f1a2a5dd"
      },
      "source": [
        "traindf[\"tokenized\"] = traindf['clean_text'].apply(lambda x : tokenizer.encode(x, max_len=SEQ_LEN))\n",
        "traindf.reset_index(inplace=True)\n",
        "traindf"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>uid</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>237</td>\n",
              "      <td>1379</td>\n",
              "      <td>positive</td>\n",
              "      <td>RT @ cyrusgosh I CAN ’ T EVEN BELIEVE THAT I ’...</td>\n",
              "      <td>RT mention cyrusgosh I CAN ’ T EVEN BELIEVE TH...</td>\n",
              "      <td>([101, 186, 10123, 33507, 171, 20728, 10251, 1...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14202</td>\n",
              "      <td>35969</td>\n",
              "      <td>positive</td>\n",
              "      <td>@ gArmygirl @ peaceforchange # PakistanZindaba...</td>\n",
              "      <td>mention gArmygirl mention peaceforchange hasht...</td>\n",
              "      <td>([101, 33507, 47243, 14996, 92507, 33507, 2810...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1136</td>\n",
              "      <td>24314</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@ BabarAbidi @ uzair251 @ zartajgulwazir Yar m...</td>\n",
              "      <td>mention BabarAbidi mention uzair251 mention za...</td>\n",
              "      <td>([101, 33507, 15688, 43221, 78489, 10116, 3350...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16740</td>\n",
              "      <td>12400</td>\n",
              "      <td>negative</td>\n",
              "      <td>RT @ aleeshadontcare Baap ki izzat beti k hath...</td>\n",
              "      <td>RT mention aleeshadontcare Baap ki izzat beti ...</td>\n",
              "      <td>([101, 186, 10123, 33507, 11372, 38806, 11272,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14213</td>\n",
              "      <td>36030</td>\n",
              "      <td>positive</td>\n",
              "      <td>@ sarbjee52789190 @ BabyK34446271 Jhoot gali g...</td>\n",
              "      <td>mention sarbjee52789190 mention BabyK34446271 ...</td>\n",
              "      <td>([101, 33507, 10148, 50579, 76083, 92161, 1130...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13595</th>\n",
              "      <td>5061</td>\n",
              "      <td>13111</td>\n",
              "      <td>negative</td>\n",
              "      <td>RT @ sza Holding ur tongue so exhausting !!! F...</td>\n",
              "      <td>RT mention sza Holding ur tongue so exhausting...</td>\n",
              "      <td>([101, 186, 10123, 33507, 61048, 10113, 29008,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13596</th>\n",
              "      <td>944</td>\n",
              "      <td>4654</td>\n",
              "      <td>positive</td>\n",
              "      <td>@ AbbassFr Budget tu pass ho jaye ga . Har baa...</td>\n",
              "      <td>mention AbbassFr Budget tu pass ho jaye ga . H...</td>\n",
              "      <td>([101, 33507, 11357, 21322, 10107, 71843, 2529...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13597</th>\n",
              "      <td>12931</td>\n",
              "      <td>30610</td>\n",
              "      <td>positive</td>\n",
              "      <td>@ narendramodi177 Congratulations all of you ....</td>\n",
              "      <td>mention narendramodi177 Congratulations all of...</td>\n",
              "      <td>([101, 33507, 90086, 96086, 11033, 10703, 3426...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13598</th>\n",
              "      <td>10098</td>\n",
              "      <td>23584</td>\n",
              "      <td>positive</td>\n",
              "      <td>RT @ AshVerma111 So sweet .. thank you soo muc...</td>\n",
              "      <td>RT mention AshVerma111 So sweet .. thank you s...</td>\n",
              "      <td>([101, 186, 10123, 33507, 83244, 12563, 10369,...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13599</th>\n",
              "      <td>8839</td>\n",
              "      <td>20427</td>\n",
              "      <td>neutral</td>\n",
              "      <td># askstarsports semeephainal pahunch sakatee h...</td>\n",
              "      <td>hashtag askstarsports semeephainal pahunch sak...</td>\n",
              "      <td>([101, 10393, 32493, 10240, 54031, 12819, 3656...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13600 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index    uid  ...                                          tokenized label\n",
              "0        237   1379  ...  ([101, 186, 10123, 33507, 171, 20728, 10251, 1...     2\n",
              "1      14202  35969  ...  ([101, 33507, 47243, 14996, 92507, 33507, 2810...     2\n",
              "2       1136  24314  ...  ([101, 33507, 15688, 43221, 78489, 10116, 3350...     1\n",
              "3      16740  12400  ...  ([101, 186, 10123, 33507, 11372, 38806, 11272,...     0\n",
              "4      14213  36030  ...  ([101, 33507, 10148, 50579, 76083, 92161, 1130...     2\n",
              "...      ...    ...  ...                                                ...   ...\n",
              "13595   5061  13111  ...  ([101, 186, 10123, 33507, 61048, 10113, 29008,...     0\n",
              "13596    944   4654  ...  ([101, 33507, 11357, 21322, 10107, 71843, 2529...     2\n",
              "13597  12931  30610  ...  ([101, 33507, 90086, 96086, 11033, 10703, 3426...     2\n",
              "13598  10098  23584  ...  ([101, 186, 10123, 33507, 83244, 12563, 10369,...     2\n",
              "13599   8839  20427  ...  ([101, 10393, 32493, 10240, 54031, 12819, 3656...     1\n",
              "\n",
              "[13600 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us6LfvxsH3g8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "5de81f0a-b471-4e56-bf41-ffccfa8a5ed5"
      },
      "source": [
        "testdf[\"tokenized\"] = testdf['clean_text'].apply(lambda x : tokenizer.encode(x, max_len=SEQ_LEN))\n",
        "testdf.reset_index(inplace=True)\n",
        "testdf"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>uid</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>label</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7135</td>\n",
              "      <td>16677</td>\n",
              "      <td>positive</td>\n",
              "      <td>@ asadowaisi @ aimim _ national @ narendramodi...</td>\n",
              "      <td>mention asadowaisi mention aimim _ national me...</td>\n",
              "      <td>2</td>\n",
              "      <td>([101, 33507, 81387, 53418, 14553, 33507, 5604...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7291</td>\n",
              "      <td>16986</td>\n",
              "      <td>positive</td>\n",
              "      <td>Hamare nabinji odissa c m congratulations apko...</td>\n",
              "      <td>Hamare nabinji odissa c m congratulations apko...</td>\n",
              "      <td>2</td>\n",
              "      <td>([101, 96474, 10112, 10132, 16473, 10775, 1031...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4608</td>\n",
              "      <td>12168</td>\n",
              "      <td>negative</td>\n",
              "      <td>@ Mahende67015515 @ RahulGandhi maa ko pairo s...</td>\n",
              "      <td>mention Mahende67015515 mention RahulGandhi ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>([101, 33507, 29325, 13201, 11211, 48205, 3746...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3021</td>\n",
              "      <td>6598</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@ alehsfeemi @ MrDannyxX007 Ab kia kia es me s...</td>\n",
              "      <td>mention alehsfeemi mention MrDannyxX007 Ab kia...</td>\n",
              "      <td>1</td>\n",
              "      <td>([101, 33507, 11372, 22394, 14601, 32080, 3350...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11178</td>\n",
              "      <td>26490</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@_ pallavighosh Food packet choro gaadi pe kap...</td>\n",
              "      <td>mention_ pallavighosh Food packet choro gaadi ...</td>\n",
              "      <td>1</td>\n",
              "      <td>([101, 33507, 168, 29330, 25768, 26009, 10310,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3395</th>\n",
              "      <td>10197</td>\n",
              "      <td>23883</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@ ZeeNewsHindi Neetesh kumar palti maar Baba h...</td>\n",
              "      <td>mention ZeeNewsHindi Neetesh kumar palti maar ...</td>\n",
              "      <td>1</td>\n",
              "      <td>([101, 33507, 68843, 72078, 102482, 10554, 348...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3396</th>\n",
              "      <td>10777</td>\n",
              "      <td>25574</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@ ifOnlyKewal Jiske naam pe filme chlti thi na...</td>\n",
              "      <td>mention ifOnlyKewal Jiske naam pe filme chlti ...</td>\n",
              "      <td>1</td>\n",
              "      <td>([101, 33507, 12277, 10263, 10454, 10550, 3787...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3397</th>\n",
              "      <td>4726</td>\n",
              "      <td>12528</td>\n",
              "      <td>negative</td>\n",
              "      <td>@ ZarmanB @ WeUttarPradesh @ bareillypolice @ ...</td>\n",
              "      <td>mention ZarmanB mention WeUttarPradesh mention...</td>\n",
              "      <td>0</td>\n",
              "      <td>([101, 33507, 10339, 26226, 10457, 33507, 1195...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3398</th>\n",
              "      <td>7599</td>\n",
              "      <td>17592</td>\n",
              "      <td>negative</td>\n",
              "      <td>@ Nidhi @ JhaSanjay NDTV wale kutte ki maut au...</td>\n",
              "      <td>mention Nidhi mention JhaSanjay NDTV wale kutt...</td>\n",
              "      <td>0</td>\n",
              "      <td>([101, 33507, 92181, 11924, 33507, 178, 68398,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3399</th>\n",
              "      <td>6806</td>\n",
              "      <td>16054</td>\n",
              "      <td>positive</td>\n",
              "      <td>RT @ ALMFAIZ1968 Goutam gambir from today I am...</td>\n",
              "      <td>RT mention ALMFAIZ1968 Goutam gambir from toda...</td>\n",
              "      <td>2</td>\n",
              "      <td>([101, 186, 10123, 33507, 10164, 10147, 13369,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3400 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index    uid  ... label                                          tokenized\n",
              "0      7135  16677  ...     2  ([101, 33507, 81387, 53418, 14553, 33507, 5604...\n",
              "1      7291  16986  ...     2  ([101, 96474, 10112, 10132, 16473, 10775, 1031...\n",
              "2      4608  12168  ...     0  ([101, 33507, 29325, 13201, 11211, 48205, 3746...\n",
              "3      3021   6598  ...     1  ([101, 33507, 11372, 22394, 14601, 32080, 3350...\n",
              "4     11178  26490  ...     1  ([101, 33507, 168, 29330, 25768, 26009, 10310,...\n",
              "...     ...    ...  ...   ...                                                ...\n",
              "3395  10197  23883  ...     1  ([101, 33507, 68843, 72078, 102482, 10554, 348...\n",
              "3396  10777  25574  ...     1  ([101, 33507, 12277, 10263, 10454, 10550, 3787...\n",
              "3397   4726  12528  ...     0  ([101, 33507, 10339, 26226, 10457, 33507, 1195...\n",
              "3398   7599  17592  ...     0  ([101, 33507, 92181, 11924, 33507, 178, 68398,...\n",
              "3399   6806  16054  ...     2  ([101, 186, 10123, 33507, 10164, 10147, 13369,...\n",
              "\n",
              "[3400 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kLDX5g3RYAb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "90182799-90ef-4efa-ed7f-38f7ed0f27fb"
      },
      "source": [
        "import keras as keras\n",
        "import keras.backend as K\n",
        "from keras.models import load_model\n",
        "\n",
        "from keras_bert import load_trained_model_from_checkpoint, load_vocabulary\n",
        "from keras_bert import Tokenizer\n",
        "from keras_bert import AdamWarmup, calc_train_steps\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import gc"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOWrH1rNRZwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEQ_LEN = 128\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 5\n",
        "LR = 1e-4\n",
        "\n",
        "pretrained_path = 'pretrained_bert'\n",
        "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
        "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
        "vocab_path = os.path.join(pretrained_path, 'vocab.txt')\n",
        "\n",
        "DATA_COLUMN = 'clean_text'\n",
        "LABEL_COLUMN = 'label'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9lYHYo7Rezw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_dict = load_vocabulary(vocab_path)\n",
        "tokenizer = Tokenizer(token_dict)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ineO6SJRo-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_data(data_df):\n",
        "    global tokenizer\n",
        "    indices, targets = [], []\n",
        "    for i in tqdm(range(len(data_df))):\n",
        "        ids, segments = tokenizer.encode(data_df[DATA_COLUMN][i], max_len=SEQ_LEN)\n",
        "        indices.append(ids)\n",
        "        targets.append(data_df[LABEL_COLUMN][i])\n",
        "    items = list(zip(indices, targets))\n",
        "    np.random.shuffle(items)\n",
        "    indices, targets = zip(*items)\n",
        "    indices = np.array(indices)\n",
        "    return [indices, np.zeros_like(indices)], np.array(targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENNkkSSJRxHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(data_df):\n",
        "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
        "    data_x, data_y = convert_data(data_df)\n",
        "    return data_x, data_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkQVSOUYRy3F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4e649b3-c9fb-427b-caaa-aa545a342497"
      },
      "source": [
        "train_x, train_y = load_data(traindf)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 13600/13600 [00:05<00:00, 2435.35it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dquiDXCFR6q-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "48716419-b0b9-4529-e017-ce52130fc56d"
      },
      "source": [
        "pd.Series(train_y).value_counts().plot(kind = 'bar')"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa8fdf2e588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD1CAYAAAC87SVQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpKz2mdqVhpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_trained_model_from_checkpoint(\n",
        "        config_path,\n",
        "        checkpoint_path,\n",
        "        training=True,\n",
        "        trainable=True,\n",
        "        seq_len=SEQ_LEN,\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl-xCHVBWguR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "29c856a4-803f-4498-8e78-7c73298a69ef"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_18\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input-Token (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)      [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token (TokenEmbedding [(None, 128, 768), ( 91812096    Input-Token[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)   (None, 128, 768)     1536        Input-Segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)   (None, 128, 768)     0           Embedding-Token[0][0]            \n",
            "                                                                 Embedding-Segment[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmb (None, 128, 768)     98304       Embedding-Token-Segment[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)     (None, 128, 768)     0           Embedding-Position[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalizat (None, 128, 768)     1536        Embedding-Dropout[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     2362368     Embedding-Norm[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Embedding-Norm[0][0]             \n",
            "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-1-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-2-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-3-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-4-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-5-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-6-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-7-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-8-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-9-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Dropout  (None, 128, 768)     0           Encoder-10-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Add (Add (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Dropout  (None, 128, 768)     0           Encoder-11-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Add (Add (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Dropout  (None, 128, 768)     0           Encoder-12-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Add (Add (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "MLM-Dense (Dense)               (None, 128, 768)     590592      Encoder-12-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "MLM-Norm (LayerNormalization)   (None, 128, 768)     1536        MLM-Dense[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Extract (Extract)               (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "MLM-Sim (EmbeddingSimilarity)   (None, 128, 119547)  119547      MLM-Norm[0][0]                   \n",
            "                                                                 Embedding-Token[0][1]            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Masked (InputLayer)       [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "NSP-Dense (Dense)               (None, 768)          590592      Extract[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "MLM (Masked)                    (None, 128, 119547)  0           MLM-Sim[0][0]                    \n",
            "                                                                 Input-Masked[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "NSP (Dense)                     (None, 2)            1538        NSP-Dense[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 178,271,741\n",
            "Trainable params: 178,271,741\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45_wfI0NWEzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = model.inputs[:2]\n",
        "dense = model.get_layer('NSP-Dense').output\n",
        "outputs = keras.layers.Dense(units=3, activation='softmax')(dense)\n",
        "model = keras.models.Model(inputs, outputs)\n",
        "model.compile(\n",
        "        RAdam(lr=LR),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['sparse_categorical_accuracy'],\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc9KIcgKTzRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @title Initialize Variables\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "sess = K.get_session()\n",
        "uninitialized_variables = set([i.decode('ascii') for i in sess.run(tf.report_uninitialized_variables())])\n",
        "init_op = tf.variables_initializer(\n",
        "    [v for v in tf.global_variables() if v.name.split(':')[0] in uninitialized_variables]\n",
        ")\n",
        "sess.run(init_op)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urpGLbCGVBDy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f31db4e1-6b00-4740-f4cf-0821638096f6"
      },
      "source": [
        "# @title Fit\n",
        "\n",
        "model.fit(\n",
        "    train_x,\n",
        "    train_y,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13600 samples\n",
            "Epoch 1/5\n",
            " 7168/13600 [==============>...............] - ETA: 6:39 - loss: 0.8855 - sparse_categorical_accuracy: 0.5739"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl0fiYVkhnaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_x, test_y = load_data(testdf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H4TaV-iW6vD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicts = model.predict(test_x, verbose=True).argmax(axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsxcTi2whzrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @title Accuracy\n",
        "\n",
        "print(np.sum(test_y == predicts) / test_y.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEPcwqy6iTsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "validdf = pd.read_json('valid.json')\n",
        "validdf = clean(validdf)\n",
        "validdf['label'] = 0 #because I didn't want to write the entire load_data function\n",
        "valid_x, valid_y = load_data(validdf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa622Ynxi4z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicts = model.predict(valid_x, verbose=True).argmax(axis=-1)\n",
        "output = le.inverse_transform(predicts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5cFwz3FnEY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('output.csv', 'w') as f:\n",
        "    for i in range(len(output.tolist())):\n",
        "        f.write(f\"{validdf.loc[i]['uid']},{output[i]}\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYgkKYMCkkGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp output.csv drive/My\\ Drive/Hinglish/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO1dG0ASln-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}