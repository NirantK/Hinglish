{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NoPretrainHinglishBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "41220948cfe6475e923e00f8c335acb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bad6b48a328e4ab1beb9ac2d6e1b3a52",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3083aa70d81e470da2db44f452537acd",
              "IPY_MODEL_8ec1a6d29c4c4fff89976a9bbdb72539"
            ]
          }
        },
        "bad6b48a328e4ab1beb9ac2d6e1b3a52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3083aa70d81e470da2db44f452537acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dba4669bcfb041d09bd68119f472a31b",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 569,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 569,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_12ad34e727a3467590c08d365bcd2f7c"
          }
        },
        "8ec1a6d29c4c4fff89976a9bbdb72539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5c5e0cdb360744d5b8a936ee80cb1032",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 569/569 [00:00&lt;00:00, 16.5kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7577edcac7642b5a2db0dc5a06bb51c"
          }
        },
        "dba4669bcfb041d09bd68119f472a31b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "12ad34e727a3467590c08d365bcd2f7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c5e0cdb360744d5b8a936ee80cb1032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7577edcac7642b5a2db0dc5a06bb51c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3021259c9d14067a47269046766c12e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_939093a00739463f8c54bc3faa9be063",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a5ba18bb31cf4c3b919beb36cab5c324",
              "IPY_MODEL_7061f885f3e248df93458c65386a39fb"
            ]
          }
        },
        "939093a00739463f8c54bc3faa9be063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5ba18bb31cf4c3b919beb36cab5c324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_db4ee9fad3ed4c419ba7b463a097ad93",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 714314041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714314041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3002a0d13a1f460e88d198355128ca04"
          }
        },
        "7061f885f3e248df93458c65386a39fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_84ebed3cbe104011890296a29189fff6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 714M/714M [01:02&lt;00:00, 11.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7355515d11347e58e6b9e4740a58c57"
          }
        },
        "db4ee9fad3ed4c419ba7b463a097ad93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3002a0d13a1f460e88d198355128ca04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84ebed3cbe104011890296a29189fff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7355515d11347e58e6b9e4740a58c57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NirantK/Hinglish/blob/BERT/NoPretrainHinglishBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wG9nEfIxAlaP",
        "colab_type": "text"
      },
      "source": [
        "# Hinglish BERT\n",
        " \n",
        "Pre-train and Finetune Multilingual BERT for Hinglish twitter data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWe5k0THAhRC",
        "colab_type": "code",
        "outputId": "f6a5cecd-c235-4de1-8176-601ae6cbe4e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# Getting Multilingial BERT models. This one is multilingual cased \n",
        "!wget https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
        "!unzip multi_cased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-01 13:40:53--  https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.68.128, 2404:6800:4003:c04::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.68.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 662903077 (632M) [application/zip]\n",
            "Saving to: ‘multi_cased_L-12_H-768_A-12.zip’\n",
            "\n",
            "multi_cased_L-12_H- 100%[===================>] 632.19M   135MB/s    in 4.7s    \n",
            "\n",
            "2020-02-01 13:40:58 (135 MB/s) - ‘multi_cased_L-12_H-768_A-12.zip’ saved [662903077/662903077]\n",
            "\n",
            "Archive:  multi_cased_L-12_H-768_A-12.zip\n",
            "   creating: multi_cased_L-12_H-768_A-12/\n",
            "  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: multi_cased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: multi_cased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR-qs_adAp5s",
        "colab_type": "code",
        "outputId": "72a19c75-6008-428a-d0d2-61e2eb452568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUGkvyim_KF1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8bf77ca3-2a6e-46f5-9789-45f5ce687f68"
      },
      "source": [
        "!cp drive/My\\ Drive/Hinglish/pretrained_bert500k.tar.gz .\n",
        "!mv pretrained_bert500k.tar.gz pretrained_bert.tar.gz\n",
        "!tar -xvf pretrained_bert.tar.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pretrained_bert/\n",
            "pretrained_bert/bert_model.ckpt.data-00000-of-00001\n",
            "pretrained_bert/bert_config.json\n",
            "pretrained_bert/bert_model.ckpt.meta\n",
            "pretrained_bert/vocab.txt\n",
            "pretrained_bert/bert_model.ckpt.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu5HsFpDCKQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def clean(df):\n",
        "    df[\"clean_text\"] = df[\"text\"]\n",
        "    df[\"clean_text\"] = (\n",
        "        (df[\"clean_text\"])\n",
        "            .apply(lambda text: re.sub(r\"RT\\s@\\w+\", \"\", text)) #Removes RTS\n",
        "            .apply(lambda text: re.sub(r\"@\", \"mention\", text)) # Replaces @ with mention\n",
        "            .apply(lambda text: re.sub(r\"#\", \"hashtag\", text)) # Replaces # with hastag\n",
        "            .apply(lambda text: re.sub(r\"http\\S+\", \"\", text)) # Removes URL\n",
        "        )\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ley3LgtqCZTQ",
        "colab_type": "code",
        "outputId": "2dd8de8e-0721-480f-8db9-042590ad003f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# train and test json are available here https://drive.google.com/open?id=1Ij_THj01L-2Y1a8woOn9vXmHosW83e3R\n",
        "# They are labeled twitter jsons with sentiments [\"positive\", \"negative\", \"neutral\"] attached to them\n",
        "traindf= pd.read_json(\"drive/My Drive/Hinglish/interim/train.json\")\n",
        "testdf= pd.read_json(\"drive/My Drive/Hinglish/interim/test.json\")\n",
        "validdf = pd.read_json(\"valid.json\")\n",
        "validdf['sentiment'] = 0\n",
        "\n",
        "traindf = clean(traindf)\n",
        "testdf = clean(testdf)\n",
        "validdf = clean(validdf)\n",
        "len(traindf), len(testdf), len(validdf)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13600, 3400, 3000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRgSMYh_FMbV",
        "colab_type": "code",
        "outputId": "8016623e-7145-4d21-c690-7d8fb03f7d2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install pytorch-transformers\n",
        "!pip install tensorboardX\n",
        "!pip install transformers"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 27.3MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 32.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30kB 19.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61kB 11.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71kB 10.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102kB 10.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112kB 10.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122kB 10.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133kB 10.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143kB 10.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153kB 10.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163kB 10.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174kB 10.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 10.4MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 24.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 31.1MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 35.5MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 36.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 37.6MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 34.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 30.5MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 32.1MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 28.2MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 26.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 26.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 26.7MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 26.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 26.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 26.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 26.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 26.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 26.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 26.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 26.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 26.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.17.5)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\r\u001b[K     |▍                               | 10kB 25.6MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 32.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30kB 39.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 43.2MB/s eta 0:00:01\r\u001b[K     |██                              | 51kB 45.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61kB 48.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71kB 50.1MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 51.3MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92kB 52.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 102kB 53.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 112kB 53.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 122kB 53.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 133kB 53.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 143kB 53.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 153kB 53.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 163kB 53.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 174kB 53.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 184kB 53.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 194kB 53.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 204kB 53.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 215kB 53.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 225kB 53.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 235kB 53.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 245kB 53.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 256kB 53.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 266kB 53.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 276kB 53.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 286kB 53.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 296kB 53.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 307kB 53.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 317kB 53.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 327kB 53.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 337kB 53.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 348kB 53.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 358kB 53.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 368kB 53.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 378kB 53.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 389kB 53.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 399kB 53.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 409kB 53.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 419kB 53.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 430kB 53.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 440kB 53.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 450kB 53.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 460kB 53.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 471kB 53.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 481kB 53.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 491kB 53.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 501kB 53.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 512kB 53.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 522kB 53.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 532kB 53.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 542kB 53.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 552kB 53.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 563kB 53.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 573kB 53.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 583kB 53.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 593kB 53.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 604kB 53.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 614kB 53.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 624kB 53.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 634kB 53.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 645kB 53.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 655kB 53.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 665kB 53.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 675kB 53.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 686kB 53.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 696kB 53.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 706kB 53.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 716kB 53.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 727kB 53.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 737kB 53.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 747kB 53.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 757kB 53.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 768kB 53.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 778kB 53.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 788kB 53.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 798kB 53.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 808kB 53.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 819kB 53.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 829kB 53.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 839kB 53.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 849kB 53.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 860kB 53.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 870kB 53.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.10.47)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.28.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2019.11.28)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.13.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.2.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->pytorch-transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->pytorch-transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=9766cb262de29ec96af8ab60e9b497fa21f5c39a1e7b2dbb911e9a646cf004c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, pytorch-transformers\n",
            "Successfully installed pytorch-transformers-1.2.0 sacremoses-0.0.38 sentencepiece-0.1.85\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 12.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.17.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (42.0.2)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.0\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 35.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 46.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.47)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (2.6.1)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "Successfully installed tokenizers-0.0.11 transformers-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTOoT2R2FPum",
        "colab_type": "code",
        "outputId": "0c9465ab-6793-49d1-8469-2fcc870b0284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9KAzbegvsfn",
        "colab_type": "code",
        "outputId": "32473f93-169c-474f-bd4d-db41f1f1fd4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "traindf.isnull().sum(),testdf.isnull().sum(),validdf.isnull().sum()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(uid           0\n",
              " sentiment     0\n",
              " text          0\n",
              " clean_text    0\n",
              " dtype: int64, uid           0\n",
              " sentiment     0\n",
              " text          0\n",
              " clean_text    0\n",
              " dtype: int64, sentiment     0\n",
              " text          0\n",
              " uid           0\n",
              " clean_text    0\n",
              " dtype: int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57aQP3KOFd1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = traindf['clean_text']\n",
        "labels = traindf['sentiment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIrKZ7CtFgbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(labels)\n",
        "labels = le.transform(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-OUVpPcFg_F",
        "colab_type": "code",
        "outputId": "fb6dc4ec-d008-4b58-daab-8c058c76c510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer= BertTokenizer.from_pretrained(\"pretrained_bert\")\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "print (\"Tokenize the first sentence:\")\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n",
            "Tokenize the first sentence:\n",
            "['r', '##t', 'mention', 'c', '##yr', '##us', '##gos', '##h', 'i', 'can', '[UNK]', 't', 'even', 'believe', 'that', 'i', '[UNK]', 've', 'got', 'pictures', 'with', 'mile', '##y', 'fu', '##cking', 'c', '##yr', '##us', 'this', 'is', 'a', 'fu', '##cking', 'dream', 'come', 'true', '[UNK]', 'i', 'love', 'you', 'more', 'th', '[UNK]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8PzIpelFpFM",
        "colab_type": "code",
        "outputId": "4bf12993-ae75-4182-eed7-b9103f50a68b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  RT mention UAAPconfessions Love looks good on Maddie !!! Ako lang ba yung sobrang masaya kasi may zolo sya ? Before with the past Z medyo lowkey s …  \n",
            "Token IDs: [101, 186, 10123, 33507, 171, 20728, 10251, 16385, 10237, 177, 10944, 100, 188, 13246, 30587, 10189, 177, 100, 10323, 19556, 54156, 10169, 21128, 10157, 11005, 72453, 171, 20728, 10251, 10531, 10124, 169, 11005, 72453, 51442, 10678, 22024, 100, 177, 16138, 13028, 10798, 77586, 100, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N3p_pO5Fp0p",
        "colab_type": "code",
        "outputId": "7804e389-a953-4347-f767-6e73c88edc7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Thu-toJWFrkV",
        "colab_type": "code",
        "outputId": "163c5e7c-371b-476f-ce2a-604a491ef862",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 128\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 128 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcgd5xMUFtf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0oQpHs6FvSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx_J_PCIFy3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk9ZDWItFzap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I49YuRdF02s",
        "colab_type": "code",
        "outputId": "63cfedec-eb69-469a-c213-1e2e5a65826e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "41220948cfe6475e923e00f8c335acb4",
            "bad6b48a328e4ab1beb9ac2d6e1b3a52",
            "3083aa70d81e470da2db44f452537acd",
            "8ec1a6d29c4c4fff89976a9bbdb72539",
            "dba4669bcfb041d09bd68119f472a31b",
            "12ad34e727a3467590c08d365bcd2f7c",
            "5c5e0cdb360744d5b8a936ee80cb1032",
            "c7577edcac7642b5a2db0dc5a06bb51c",
            "b3021259c9d14067a47269046766c12e",
            "939093a00739463f8c54bc3faa9be063",
            "a5ba18bb31cf4c3b919beb36cab5c324",
            "7061f885f3e248df93458c65386a39fb",
            "db4ee9fad3ed4c419ba7b463a097ad93",
            "3002a0d13a1f460e88d198355128ca04",
            "84ebed3cbe104011890296a29189fff6",
            "e7355515d11347e58e6b9e4740a58c57"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-cased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--2 for binary classification. \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41220948cfe6475e923e00f8c335acb4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=569, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3021259c9d14067a47269046766c12e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=714314041, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBekTZy0F4mL",
        "colab_type": "code",
        "outputId": "2d9b3ef1-5581-4200-a465-bc0ecc9deb79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (119547, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (3, 768)\n",
            "classifier.bias                                                 (3,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIaI36AjF5Pe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-0i9y2BF8as",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhQ0I2yBF94e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLUut02VGAEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGSp_0uWGCKQ",
        "colab_type": "code",
        "outputId": "208d5be6-50ee-41b7-d723-3c8224dd47ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    383.    Elapsed: 0:00:30.\n",
            "  Batch    80  of    383.    Elapsed: 0:01:01.\n",
            "  Batch   120  of    383.    Elapsed: 0:01:33.\n",
            "  Batch   160  of    383.    Elapsed: 0:02:05.\n",
            "  Batch   200  of    383.    Elapsed: 0:02:37.\n",
            "  Batch   240  of    383.    Elapsed: 0:03:10.\n",
            "  Batch   280  of    383.    Elapsed: 0:03:42.\n",
            "  Batch   320  of    383.    Elapsed: 0:04:14.\n",
            "  Batch   360  of    383.    Elapsed: 0:04:46.\n",
            "\n",
            "  Average training loss: 0.93\n",
            "  Training epcoh took: 0:05:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.61\n",
            "  Validation took: 0:00:12\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    383.    Elapsed: 0:00:32.\n",
            "  Batch    80  of    383.    Elapsed: 0:01:04.\n",
            "  Batch   120  of    383.    Elapsed: 0:01:36.\n",
            "  Batch   160  of    383.    Elapsed: 0:02:09.\n",
            "  Batch   200  of    383.    Elapsed: 0:02:41.\n",
            "  Batch   240  of    383.    Elapsed: 0:03:13.\n",
            "  Batch   280  of    383.    Elapsed: 0:03:45.\n",
            "  Batch   320  of    383.    Elapsed: 0:04:17.\n",
            "  Batch   360  of    383.    Elapsed: 0:04:50.\n",
            "\n",
            "  Average training loss: 0.80\n",
            "  Training epcoh took: 0:05:08\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.62\n",
            "  Validation took: 0:00:12\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    383.    Elapsed: 0:00:32.\n",
            "  Batch    80  of    383.    Elapsed: 0:01:04.\n",
            "  Batch   120  of    383.    Elapsed: 0:01:37.\n",
            "  Batch   160  of    383.    Elapsed: 0:02:09.\n",
            "  Batch   200  of    383.    Elapsed: 0:02:41.\n",
            "  Batch   240  of    383.    Elapsed: 0:03:13.\n",
            "  Batch   280  of    383.    Elapsed: 0:03:46.\n",
            "  Batch   320  of    383.    Elapsed: 0:04:18.\n",
            "  Batch   360  of    383.    Elapsed: 0:04:50.\n",
            "\n",
            "  Average training loss: 0.70\n",
            "  Training epcoh took: 0:05:08\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.62\n",
            "  Validation took: 0:00:12\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    383.    Elapsed: 0:00:32.\n",
            "  Batch    80  of    383.    Elapsed: 0:01:04.\n",
            "  Batch   120  of    383.    Elapsed: 0:01:37.\n",
            "  Batch   160  of    383.    Elapsed: 0:02:09.\n",
            "  Batch   200  of    383.    Elapsed: 0:02:41.\n",
            "  Batch   240  of    383.    Elapsed: 0:03:13.\n",
            "  Batch   280  of    383.    Elapsed: 0:03:45.\n",
            "  Batch   320  of    383.    Elapsed: 0:04:18.\n",
            "  Batch   360  of    383.    Elapsed: 0:04:50.\n",
            "\n",
            "  Average training loss: 0.61\n",
            "  Training epcoh took: 0:05:08\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.63\n",
            "  Validation took: 0:00:12\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ieNRsfOGGWJ",
        "colab_type": "code",
        "outputId": "d5f60565-85f0-494a-96bc-65e7a5b992cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd3yV5f3/8dc5mWQQsvdi5ISVEELC\n3oEEBFxMGVKViv7U1n5tURFr1Wq1WKkLC2oFBdlDRVlhygqEDSFgALMgBEIIM/v3hyVtZCUYOCfJ\n+/lfrvu+7vtz8nkEPrlyDUN5eXk5IiIiIiJSKxjNHYCIiIiIiFSdCngRERERkVpEBbyIiIiISC2i\nAl5EREREpBZRAS8iIiIiUouogBcRERERqUVUwIuI1FOTJ0/GZDKRm5t7W/0LCwsxmUy8/PLLNRxZ\n9Xz11VeYTCZ2795t1jhERO4Wa3MHICJSn5lMpirfm5iYSEBAwB2MRkREagMV8CIiZvT2229X+jo5\nOZm5c+cybNgwoqOjK11zc3Or0Xf//ve/5+mnn8bOzu62+tvZ2bF3716srKxqNC4REbk5FfAiImZ0\n7733Vvq6tLSUuXPn0qZNm2uu3Uh5eTmXL1/GwcGhWu+2trbG2vrX/Tdwu8W/iIjcPs2BFxGpRTZs\n2IDJZOLbb79lxowZJCQk0Lp1a7788ksAdu7cyZ/+9Cf69u1LZGQkbdu2ZeTIkaxdu/aaZ11vDvzV\ntoyMDN566y26du1K69atuf/++9m0aVOl/tebA/+/bdu3b2fEiBFERkbSoUMHXn75ZS5fvnxNHJs3\nb2bIkCG0bt2aLl268Le//Y2DBw9iMpmYNm3abX+vTp8+zcsvv0y3bt1o1aoVPXv25PXXX+fcuXOV\n7rt06RLvvvsu8fHxREREEBMTw8CBA3n33Xcr3bd69WpGjBhB+/btiYiIoGfPnjzzzDNkZGTcdowi\nIrdDI/AiIrXQ9OnTOX/+PA8++CDu7u4EBgYCsHz5cjIyMujfvz9+fn7k5eWxePFixo8fz/vvv0/f\nvn2r9Pz/+7//w87Ojscee4zCwkI+//xznnjiCVatWoW3t/ct++/bt48VK1YwePBgBg0axJYtW5g7\ndy62tra89NJLFfdt2bKFcePG4ebmxuOPP46TkxPLli0jKSnp9r4x/5Gfn8+wYcPIzs5myJAhhIeH\ns2/fPr788ku2bdvGvHnzaNCgAQCTJk1i2bJl3H///bRp04bi4mKOHz/O1q1bK573ww8/8NRTT9Gi\nRQvGjx+Pk5MTOTk5bNq0iczMzIrvv4jI3aACXkSkFjp16hTff/89jRo1qtT++9///pqpNKNHj2bQ\noEFMnTq1ygW8t7c37733HgaDAaBiJH/+/Pk89dRTt+yfmprKggULaNGiBQAjRozg4YcfZu7cufzp\nT3/C1tYWgDfffBMbGxvmzZuHr68vAA899BDDhw+vUpw38vHHH5OZmclf//pXBg8eXNHerFkz3nrr\nrYpfSMrLy1mzZg1xcXG8+eabN3ze6tWrAZgxYwbOzs4V7VX5XoiI1DRNoRERqYUefPDBa4p3oFLx\nfvnyZc6ePUthYSGxsbGkpKRQVFRUpec//PDDFcU7QHR0NDY2Nhw/frxK/WNiYiqK96s6dOhAUVER\nJ06cACArK4vU1FTi4+MrincAW1tbxowZU6X33MjVvxQ88MADldpHjRqFs7Mzq1atAsBgMODo6Ehq\naippaWk3fJ6zszPl5eWsWLGC0tLSXxWbiMivpRF4EZFaKCQk5Lrtp06d4t1332Xt2rWcPXv2muvn\nz5/H3d39ls//5ZQQg8GAi4sL+fn5VYrvelNKrv7CkZ+fT3BwMJmZmQCEhoZec+/12qqqvLyc7Oxs\nOnTogNFYeZzK1taWoKCgincDTJw4kRdffJH+/fsTHBxM+/bt6dWrFz169Kj4Jebhhx9m3bp1TJw4\nkb/97W+0a9eOrl270r9/f1xdXW87VhGR26ECXkSkFro6f/t/lZaWMnbsWDIzMxkzZgwtW7bE2dkZ\no9HInDlzWLFiBWVlZVV6/i8L36vKy8t/Vf/qPONu6devH+3bt2fDhg0kJSXxww8/MG/ePDp27Mgn\nn3yCtbU1Hh4eLF68mO3bt7N582a2b9/O66+/znvvvcenn35Kq1atzP0xRKQeUQEvIlJH7N+/n7S0\nNP7whz/w+OOPV7p2dZcaS+Lv7w/AsWPHrrl2vbaqMhgM+Pv7c/ToUcrKyir9MlFUVER6ejpBQUGV\n+ri5uXHfffdx3333UV5ezhtvvMHMmTPZsGEDvXr1An7edrNjx4507NgR+Pn7PXjwYP71r3/x/vvv\n33a8IiLVpTnwIiJ1xNVC9Zcj3AcOHGD9+vXmCOmmAgICCAsLY8WKFRXz4uHnInvmzJm/6tlxcXGc\nPHmSJUuWVGqfPXs258+fp0+fPgAUFxdz4cKFSvcYDAaaN28OULHlZF5e3jXvaNq0Kba2tlWeViQi\nUlM0Ai8iUkeYTCZCQkKYOnUqBQUFhISEkJaWxrx58zCZTBw4cMDcIV7j+eefZ9y4cQwdOpThw4fj\n6OjIsmXLKi2gvR3jx49n5cqVvPTSS+zZsweTycT+/ftZtGgRYWFhjB07Fvh5Pn5cXBxxcXGYTCbc\n3NzIyMjgq6++wtXVle7duwPwpz/9iYKCAjp27Ii/vz+XLl3i22+/pbCwkPvuu+/XfhtERKpFBbyI\nSB1ha2vL9OnTefvtt1m4cCGFhYWEhYXxj3/8g+TkZIss4Dt37sy0adN49913+fjjj3FxcWHAgAHE\nxcUxcuRI7O3tb+u5jRo1Yu7cubz//vskJiaycOFC3N3dGTVqFE8//XTFGgJnZ2dGjRrFli1b2Lhx\nI5cvX8bT05O+ffvy+OOP4+bmBsADDzzA0qVLWbRoEWfPnsXZ2ZlmzZrx0Ucf0bt37xr7foiIVIWh\n3NJWE4mISL339ddf88c//pEPP/yQuLg4c4cjImJRNAdeRETMpqys7Jq96YuKipgxYwa2tra0a9fO\nTJGJiFguTaERERGzuXDhAv3792fgwIGEhISQl5fHsmXLOHLkCE899dR1D6sSEanvVMCLiIjZ2Nvb\n07lzZ1auXMnp06cBaNy4Ma+99hpDhw41c3QiIpZJc+BFRERERGoRzYEXEREREalFVMCLiIiIiNQi\nmgNfTWfPXqSs7O7POnJ3d+LMmQu3vlHuGuXEMikvlkc5sUzKi+VRTiyTOfJiNBpwdXW84XUV8NVU\nVlZulgL+6rvFsignlkl5sTzKiWVSXiyPcmKZLC0vmkIjIiIiIlKLqIAXEREREalFVMCLiIiIiNQi\nKuBFRERERGoRFfAiIiIiIrWICngRERERkVpEBbyIiIiISC2iAl5EREREpBZRAS8iIiIiUovoJFYL\nt+XASRatTyOvoBC3hnY80L0JHVv6mDssERERETETFfAWbMuBk8z4/hBFJWUAnCkoZMb3hwBUxIuI\niIjUU5pCY8EWrU+rKN6vKiopY9H6NDNFJCIiIiLmpgLegp0pKKxWu4iIiIjUfSrgLZh7Q7vrtttY\nGzlz7spdjkZERERELIEKeAv2QPcm2FpXTpGV0UBZaRkTP9nK8m3plJSW3aC3iIiIiNRFWsRqwa4u\nVP3lLjTN/F2Yteow89b+yOb9JxgTH07TABczRysiIiIid4MKeAvXsaUPHVv64OnpTG7u+Yr2ZwZH\nsOvIaWatOswbXybTLdKPwT2a4NTAxozRioiIiMidpgK+ljIYDLQN86RFiCtLfzjGqu2Z7DqSy9Ce\nTenUygeDwWDuEEVERETkDtAc+FrO3taaYb2a8fLYdng1asCny1L4+1e7yD590dyhiYiIiMgdoAK+\njgjyduaF0dGMSTCRnnOBP3+WxKINaRQVl5o7NBERERGpQZpCU4cYDQZ6tPGnbTNP5q75kW83/8S2\ngzmM6muidWN3c4cnIiIiIjVAI/B1UENHW8YNbMEfR0RhZTTy7rw9fLRkP2fP6wAoERERkdpOBXwd\n1jzYlb88Esv9XUPZ8+NpJk7fyqodGZSVlZs7NBERERG5TSrg6zgbayMDO4fy2qOxNPF34avVR3ht\nxg6OnSgwd2giIiIichtUwNcTXq4O/GFoJOPvbUn+xUJen7GDL1emculKiblDExEREZFq0CLWesRg\nMBDb3JtWoe4s3niUNTszSU7NZXjvZsQ299Le8SIiIiK1gEbg6yEHe2tG9gnjpTHtaORsx7++PsA/\n5u4mJ++SuUMTERERkVtQAV+Phfo2ZNKYdozsE8bREwVM+jSJr384RnFJmblDExEREZEb0BSaes5o\nNNA7OoBokydzEo+w5IdjbDmYw+i+YbQIcTN3eCIiIiLyCxqBFwAaOdkx/t5W/GFoJOVl5Uyes5tp\n3xzg3MUic4cmIiIiIv9DBbxU0qqxO68+GsvATiFsTznFi9O2snZXFmXl2jteRERExBKogJdr2NpY\ncX+3xrz6aCzB3k58sSKVN75IJj3nvLlDExEREan3VMDLDfm6O/LHEVGMG9iC0/mX+cvn25mTeITL\nhdo7XkRERMRctIhVbspgMNCxpQ8RTdxZuP4oq7ZnsP3QKR6Ka0bbME/tHS8iIiJyl5l1BL6oqIi/\n//3vdOnShYiICIYOHcqWLVuq1HfJkiUMHDiQ1q1b06VLF15//XUuXrx4zX1lZWVMnz6dXr160bp1\nawYOHMh3331X0x+lznO0t2FMvIkXR0fj1MCGDxfv558L9pKbf9ncoYmIiIjUK2Yt4J9//nlmzJjB\noEGDmDhxIkajkXHjxrFr166b9psxYwYTJkzA09OT559/ngceeIAFCxbw5JNPUv6LxZbvvvsukydP\npkuXLkyaNAk/Pz+effZZli9ffic/Wp3VxN+Fl8e2Y3ivpqSm5zPpk20s23KcklLtHS8iIiJyNxjK\nf1nx3iV79+5lyJAhvPDCC4wdOxaAwsJCBgwYgJeXF7Nmzbpuv6KiIjp16kTLli35/PPPK6ZwrF27\nlvHjx/Phhx8SFxcHQE5ODr1792bEiBFMnDgRgPLyckaNGsWJEydYvXo1RmP1foc5c+YCZWV3/1vm\n6elMbq5lLSLNK7jCV6uPkHw4Fz8PR0b3DcMU5GrusO4aS8yJKC+WSDmxTMqL5VFOLJM58mI0GnB3\nd7rx9bsYSyXLly/HxsaGIUOGVLTZ2dkxePBgkpOTOXXq1HX7HTlyhPPnz9O/f/9K86979uyJg4ND\npekxq1evpri4mIceeqiizWAwMGLECLKysti7d+8d+GT1h1tDe/7fA615ZnAEhUWlvDV7F58tS+H8\nJe0dLyIiInKnmK2AT0lJITQ0FEdHx0rtERERlJeXk5KSct1+RUU/F4d2dnbXXLO3t+fAgQOV3uHk\n5ERoaOg17wA4ePDgr/oM8rM2TT14/bH29O8QzJYDJ3lx2lY27snW3vEiIiIid4DZCvjc3Fy8vLyu\naff09AS44Qh8cHAwBoOBnTt3Vmo/evQoeXl5lfrl5ubi4eFR7XdI9dnZWjG4RxNe+U0Mfh6O/Pv7\nQ7w1ayeZuRfMHZqIiIhInWK2bSSvXLmCjY3NNe1XR9YLCwuv28/NzY1+/fqxcOFCGjduTO/evcnJ\nyeG1117DxsamUr8rV65ga2tb7XfczM3mI91pnp7OZnt3VXl6OhMR7sOaHel89s1B/vLv7dzXvQnD\n+5iwt6t7u5bWhpzUR8qL5VFOLJPyYnmUE8tkaXkxW0Vlb29PcXHxNe1Xi+rrTZG56tVXX+XKlSu8\n+eabvPnmmwAMGjSIoKCgSttQ2tvbV0y5qe47bkSLWKsmMtSN1x+LZf66NBau/ZF1yZmM7BtGm6bX\n/kWktqptOakvlBfLo5xYJuXF8ignlskSF7GarYD39PS87hSW3NxcgOtOr7nK2dmZqVOnkp2dTVZW\nFn5+fvj7+zN8+HCCg4MrvWPHjh239Q759ZwdbHmkf3O6tPZl5opU3luwl7ZhnjwU1wy3hvbmDk9E\nRESkVjLbHPjw8HCOHTt2zeFLe/bsqbh+K35+fsTExODv709BQQH79++nY8eOFdebN2/OhQsXOHbs\n2HXf0bx581/7MaQKwgIb8cpvYhjcown7j55h4vRtLN+Wrr3jRURERG6D2Qr4hIQEiouLmT9/fkVb\nUVERixYtom3btnh7ewOQnZ1NWlraLZ/3zjvvYDQaGTZsWEVb7969sbGxYfbs2RVt5eXlzJkzBz8/\nPyIjI2vwE8nNWFsZ6d8hmNcfa48pqBHz1v7Iq5/vIC3rnLlDExEREalVzDaFJjIykoSEBCZPnkxu\nbi5BQUEsXryY7OzsinntABMmTCApKYnU1NSKtqlTp5KWlkZkZCRWVlYkJibyww8/8OqrrxIYGFhx\nn4+PD2PGjOGzzz6jsLCQ1q1bs3r1anbs2MG7775b7UOc5NfzaNSA3w2OYOfh08xefZg3vkimexs/\nHuzRBEf7axc1i4iIiEhlZt0W5O2332bKlCksXbqUc+fOYTKZmDZtGtHR0TftZzKZSExMJDExEYCW\nLVsyffp0unXrds29zz33HC4uLsydO5dFixYRGhrKO++8Q//+/e/IZ5JbMxgMRJs8aRHiytIfjrF6\nRybJh3MZ3qsZHVp6VzqgS0REREQqM5SX67Sd6tAuNDUvPec8M1ekcjS7gPCgRoyON+Hr7njrjmZW\nl3NSmykvlkc5sUzKi+VRTiyTJe5CozkkYnZB3s68ODqaMfEm0nMu8PKnSSzacJSi4lJzhyYiIiJi\ncereyTpSKxkNBnpE+RMV5sm8NUf4dvNxth08yei+Jlo1djd3eCIiIiIWQyPwYlFcHG0ZN7Alfxze\nBqPRyD/m7WHqkv2cPV/9U3NFRERE6iIV8GKRmoe48eojsdzXNZRdR07z0idbSUzONMv6AxERERFL\nogJeLJaNtZFBnUN57bFYGvu5MGvVYV6buYNjJwrMHZqIiIiI2aiAF4vn7erAH4ZGMv7eluSfL+T1\nGTuYtfIwl66UmDs0ERERkbtOi1ilVjAYDMQ296ZVqDuLNxxlzc5MdqSeYkRcM2LCvbR3vIiIiNQb\nGoGXWsXB3pqRfcN46eF2NHKy4+OlB/jHvD3knL1k7tBERERE7goV8FIrhfo2ZNLD7XgorhlpWeeY\n9EkSX286RnFJmblDExEREbmjNIVGai2j0UBcu0CiTV7MSTzCko3H2Hogh9F9w2ge4mbu8ERERETu\nCI3AS63n6mzHE/e14g9DIyktK+Pvc3Yz/ZsDnLtYZO7QRERERGqcCnipM1o1due1R9szoFMISSmn\nmDhtK+t2ZVFWrr3jRUREpO5QAS91iq2NFQ90a8yrj8YS5O3EzBWpvPlFMuk5580dmoiIiEiNUAEv\ndZKvuyN/HBHFYwOacyr/Mq9+voM5iUe4UqS940VERKR20yJWqbMMBgOdWvkS0cSDhevTWLk9g+2H\nTvFQXBhtwzy0d7yIiIjUShqBlzrPqYENDyeE8+LoaBztbfhw8T7eW7CX0/mXzR2aiIiISLWpgJd6\no6m/C3/+TTuG9WrKofR8XvpkG99t/YmSUu0dLyIiIrWHptBIvWJlNBIfG0RMuBezVh1mwbo0tuw/\nyeh4E2GBjcwdnoiIiMgtaQRe6iW3hvY8/WAETz/YmitFJfxt1k4++y6F85e0d7yIiIhYNo3AS70W\n1cyTFsFufL35GCuTMth95DRDejahS2tfLXIVERERi6QReKn37GytGNKjKX/+TQw+7g78+7tDvDVr\nJ1m5F8wdmoiIiMg1VMCL/EeApxPPj2zLb/qFk3X6Iq/8ezsL1qVRWFxq7tBEREREKmgKjcj/MBoM\ndI30o00zD+avTeO7rT+RlJLDyD5hRDb1MHd4IiIiIhqBF7keZwdbHrmnORMeisLG2sg/F+zlw0X7\nyCu4Yu7QREREpJ5TAS9yE6YgV/7ySCwPdm/MvqNnmPjJNlYmpVNapr3jRURExDw0hUbkFqytjNzT\nMYTY5t7MWnWYOWt+ZNP+k/xueBRuDjbmDk9ERETqGY3Ai1SRZ6MG/G5wBP/v/lZcuFzMH9/fyMwV\nqVy8Umzu0ERERKQe0Qi8SDUYDAaiTV60CHFjZXIWX29MY2fqKYb1bkaHFt7aO15ERETuOI3Ai9yG\nBnbWPHZvK15+OAZ3lwZM/+Ygk+fs5sSZi+YOTUREROo4FfAiv0KwjzMTR0czOt7E8ZPn+fNnSSzZ\neJTiEu0dLyIiIneGptCI/EpGo4GeUf60bebB3LU/8vWm42w9kMOo+DBahbqbOzwRERGpYzQCL1JD\nXJzs+O3Aljw3vA0GA/xj7h4+Xrqf/AuF5g5NRERE6hCzjsAXFRXxz3/+k6VLl1JQUEB4eDjPPvss\nHTt2vGXfzZs3M3XqVA4fPkxZWRmNGzfm4Ycfpn///pXuM5lM1+3/yiuvMGLEiBr5HCL/q0WIG68+\nGsv3W9P5dstP7Dt6hge6NaFnlD9Goxa5ioiIyK9j1gL++eefZ+XKlYwZM4bg4GAWL17MuHHj+OKL\nL4iKirphv7Vr1/LEE08QFRXF008/DcCyZct49tlnuXjxIkOGDKl0f5cuXRg0aFCltsjIyJr/QCL/\nYWNtxaAuobRv4c2XK1OZteowm/adYEyCiRCfhuYOT0RERGoxQ3l5ebk5Xrx3716GDBnCCy+8wNix\nYwEoLCxkwIABeHl5MWvWrBv2feyxx0hNTSUxMRFbW1vg59H83r17ExwczJdffllxr8lkYsyYMUyc\nOLFG4j5z5gJlZXf/W+bp6Uxu7vm7/l65sarmpLy8nKSUU8xJPELBpSJ6tQ3g/q6NcbDXEpQ7QT8r\nlkc5sUzKi+VRTiyTOfJiNBpwd3e68fW7GEsly5cvx8bGptJouZ2dHYMHDyY5OZlTp07dsO+FCxdw\ncXGpKN4BbG1tcXFxwc7O7rp9rly5QmGh5iLL3WcwGGjfwpu/jmtPzyh/1iRnMvGTrSSl5GCm359F\nRESkFjNbAZ+SkkJoaCiOjo6V2iMiIigvLyclJeWGfWNjYzly5AhTpkwhPT2d9PR0pkyZwvHjx3nk\nkUeuuX/BggW0adOGiIgIBg4cyKpVq2r884jcioO9DaP6mnjp4Xa4ONry8dIDvDt/D6fOXjJ3aCIi\nIlKLmO1v+Lm5uXh7e1/T7unpCXDTEfjx48eTnp7Oxx9/zNSpUwFwcHDgo48+onPnzpXujYqKon//\n/gQEBHDixAlmzpzJU089xTvvvMOAAQNq8BOJVE2ob0MmPdyONTuzWLzhKJM+TWJApxASYoOwsdbG\nUCIiInJzZpsDHxcXR9OmTfn4448rtWdkZBAXF8ekSZMYNWrUdfuWlJTwwQcfcPz4cfr06UNpaSnz\n5s3j4MGDfP7550RERNzwvZcuXWLAgAGUlpaybt06DAbtCiLmc+bcZaYv3c+mPdkEeDnx5IORtG7q\nYe6wRERExIKZbQTe3t6e4uLia9qvzlO/0Vx2gNdee419+/axYMECjMafRyz79evHgAEDeOONN5gz\nZ84N+zo4ODB8+HDeeecdjh49SpMmTaoVtxaxylU1lZNH+4UTE+bJlytTeXHqJjq29GFYr6Y0dLS9\ndWe5hn5WLI9yYpmUF8ujnFgmLWL9H56entedJpObmwuAl5fXdfsVFRWxYMECevToUVG8A9jY2NC1\na1f27dtHSUnJTd/t6+sLwLlz5243fJEaFdHEndcfa8+ATsEkpeQwcfpW1u3OokyLXEVEROQXzFbA\nh4eHc+zYMS5evFipfc+ePRXXryc/P5+SkhJKS0uvuVZSUkJJScktd/bIyMgAwM3N7XZCF7kjbG2s\neKBbE/7ySCwBnk7MXJ7Km18mk3HqgrlDExEREQtitgI+ISGB4uJi5s+fX9FWVFTEokWLaNu2bcUC\n1+zsbNLS0irucXd3p2HDhqxatarSFJyLFy+ydu1awsLCsLGxASAvL++a9549e5bZs2cTEBBASEjI\nHfp0IrfPz8ORPz0UxaP3NCcn7zJ/+fd25q35kStFN//LkoiIiNQPZpsDHxkZSUJCApMnTyY3N5eg\noCAWL15MdnY2b775ZsV9EyZMICkpidTUVACsrKx45JFHmDJlCsOGDWPQoEGUlZWxYMECTp48yYQJ\nEyr6zpo1i8TERHr06IGfnx85OTnMnTuXvLw8Pvzww7v+mUWqymAw0Lm1L5FNPViwLo3lSekkHcph\nZFwYUWGe5g5PREREzMisR0G+/fbbTJkyhaVLl3Lu3DlMJhPTpk0jOjr6pv2eeOIJAgICmDlzJh9+\n+CFFRUWYTCY++OAD+vTpU3FfVFQUO3fuZP78+Zw7dw4HBwfatGnD448/fst3iFgCpwY2jO0XTpfW\nvsxccYj3F+2jTVMPHurTDA+XBuYOT0RERMzAbNtI1lbahUauuts5KSktY/WOTJb8cBSAezuH0icm\nEGsr7R3/v/SzYnmUE8ukvFge5cQyWeIuNGYdgReRqrO2MpLQPoiYcC9mrz7M/HVpbD5wktF9TYQF\nNjJ3eCIiInKXaOhOpJZxd7Hn6QcjePrB1lwuLOFvs3by7+9SuHD52nMVREREpO7RCLxILRXVzJPm\nwa58vek4K5My2HXkNEN7NqVzax+dMCwiIlKHaQRepBazt7VmaM+mvPKbGHzcHPjsuxTemr2LrNMX\nb91ZREREaiUV8CJ1QICXE8+PasvYfuFk5V7glc+SWLg+jcLiaw88ExERkdpNU2hE6gijwUC3SD/a\nNPNg/tofWbblJ7YdzGFU3zAimniYOzwRERGpIRqBF6ljGjrY8ug9LZjwUBQ21kamzN/Lh4v3kVdw\nxdyhiYiISA1QAS9SR5mCXPnLI7E82L0xe9POMPGTbazcnkFpWZm5QxMREZFfQQW8SB1mbWXkno4h\nvPZYe8ICGjEn8Qivfb6Do9kF5g5NREREbpMKeJF6wKtRA34/JIIn72tFwaUi/jpzB1+sSOXSFe0d\nLyIiUttoEatIPWEwGGgX7kXLUDeWbDzG6uQMkg/nMrxXU9q38Nbe8SIiIrWERuBF6pkGdtaMiGvG\nyw/H4N7QjmnfHGTynN2czLtk7tBERESkClTAi9RTwT7OTBzdjtF9wzh+8jwvf7qNJRuPUlyiveNF\nREQsmabQiNRjRqOBnm0DaFQZ7uEAACAASURBVBvmydw1P/L1puNsPZjD6L4mWoa6mTs8ERERuQ6N\nwIsILk52/HZQS/5veBsMwDtzd/Ovrw9w7kKhuUMTERGRX1ABLyIVWoa48eqjsdzbJZTk1FO8OH0b\na3ZmUlZWbu7QRERE5D9UwItIJTbWVtzbJZRXH21PqK8zX648zF+/2MFPJ8+bOzQRERFBBbyI3ICP\nmwP/N6wNvx3UgjMFhbw6YzuzVx/mcmGJuUMTERGp17SIVURuyGAw0KGFDxGN3Vm44SiJOzLZcegU\nD8WFEW3y1N7xIiIiZqAReBG5JQd7G0b3NTFxTDsaOtjy0ZL9TJm/l1P5l80dmoiISL2jAl5Eqqyx\nX0MmjW3HiN7NOJyZz6RPtvHt5uOUlJaZOzQREZF6Q1NoRKRarIxG+sQE0i7ci69WH2bRhqNsOXCS\nMfEmTEGu5g5PRESkztMIvIjcFldnO568vzW/HxJBcUkZb83exaffHqTgUpG5QxMREanTVMCLyK8S\n0cSD1x5rzz0dg9l6MIeJ07ayYU82ZeXaO15EROROUAEvIr+anY0VD3ZvwiuPxOLv6cTn3x/ib1/u\nJPPUBXOHJiIiUueogBeRGuPv4ciEh6J49J7mnMy7xCv/3s68tT9SWFRq7tBERETqDC1iFZEaZTAY\n6Nzal8imHixY9yPLt6WzPSWHh/qEEdXM09zhiYiI1HoagReRO8KpgQ1j+zXnhVFtsbez5v2F+3h/\n4V7OnLti7tBERERqNRXwInJHNQtoxJ/HxjCkZxMOHM9j4idb+X7bT9o7XkRE5DZpCo2I3HHWVkb6\ntQ8mJtyL2auOMH9tGlv2n2RMfDhNA1zMHZ6IiEitohF4EblrPFwa8MzgCJ5+oDWXCkt448tkPv/+\nEBcuF5s7NBERkVpDI/AictdFhXnSPMSVr384zsrtGew8nMuwXk3p1MoHg8Fg7vBEREQsmkbgRcQs\n7G2tGdqrKX/+TQzebg34dFkKb8/eRfbpi+YOTURExKKZtYAvKiri73//O126dCEiIoKhQ4eyZcuW\nKvXdvHkzo0ePpn379sTExDBs2DC+++676947f/58+vXrR+vWrYmPj2fWrFk1+TFE5FcI9HLihVHR\nPJxgIjP3An/+LImF69MoLNbe8SIiItdj9corr7xirpf/8Y9/ZNGiRQwdOpSBAweSmprKp59+SseO\nHfH19b1hv7Vr1/Lb3/4Wb29vRo0aRYcOHfjxxx/5/PPP8fHxoWXLlhX3zpkzh5dffpn27dszatQo\nysrKmDZtGo6OjkRFRVU75suXizDHCfGOjnZculR0918sN6Sc1ByDwUCIT0O6tPbl3MUi1uzMYtvB\nHLzdHPB2c6jWs5QXy6OcWCblxfIoJ5bJHHkxGAw4ONje+Hp5uTnKUdi7dy9DhgzhhRdeYOzYsQAU\nFhYyYMAAvLy8bjpK/thjj5GamkpiYiK2tj9/uKKiInr37k1wcDBffvklAFeuXKF79+5ER0fz0Ucf\nVfR/7rnnWLNmDevXr8fZ2blacZ85c4Gysrv/LfP0dCY39/xdf6/cmHJy5xz66SxfrEzlxJlLtDN5\nMiIuDFdnuyr1VV4sj3JimZQXy6OcWCZz5MVoNODu7nTj63cxlkqWL1+OjY0NQ4YMqWizs7Nj8ODB\nJCcnc+rUqRv2vXDhAi4uLhXFO4CtrS0uLi7Y2f33P/lt27aRn5/PQw89VKn/yJEjuXjxIhs2bKjB\nTyQiNSU82JW/PBLLA90asyftDBOnb2XVjgxKy7R3vIiIiNkK+JSUFEJDQ3F0dKzUHhERQXl5OSkp\nKTfsGxsby5EjR5gyZQrp6emkp6czZcoUjh8/ziOPPFJx38GDBwFo1apVpf4tW7bEaDRWXBcRy2Nt\nZWRApxBee6w9TQNc+Gr1EV6fkcyxEwXmDk1ERMSszLaNZG5uLt7e3te0e3p6Atx0BH78+PGkp6fz\n8ccfM3XqVAAcHBz46KOP6Ny5c6V32Nra0qhRo0r9r7bd7B0iYhm8GjXg2SGR7EjNZfbqw7w+Ywc9\n2vrzYLfGONjbmDs8ERGRu85sBfyVK1ewsbn2P9+rU2AKCwtv2NfW1paQkBASEhLo06cPpaWlzJs3\nj9///vd8/vnnRERE3PQdV99zs3fcyM3mI91pnp7Vm68vd55ycvf092pIj5ggvlx+iGU/HGXXkdM8\nNqgV3aL8r9k7XnmxPMqJZVJeLI9yYpksLS9mK+Dt7e0pLr729MWrRfX/zmX/pddee419+/axYMEC\njMafZwH169ePAQMG8MYbbzBnzpyKdxQVXX/VcGFh4U3fcSNaxCpXKSfmcX/nENo2cWfG8kNMnpXM\nd5uOMrqviaMnCli0Po28gkLcGtrxQPcmdGzpY+5wBf2sWCrlxfIoJ5ZJi1j/h6en53WnsOTm5gLg\n5eV13X5FRUUsWLCAHj16VBTvADY2NnTt2pV9+/ZRUlJS8Y7i4mLy8/OveUZ+fv4N3yEili3Yx5mX\nxrRjVN8wjp0o4MXpW/lsWQpnCgopB84UFDLj+0NsOXDS3KGKiIjUOLMV8OHh4Rw7doyLFyufurhn\nz56K69eTn59PSUkJpaXXHvJSUlJCSUkJV3fGbN68OQD79++vdN/+/fspKyuruC4itY/RaKBX2wD+\nOq4DNlZGSn/xl7GikjIWrU8zU3QiIiJ3jtkK+ISEBIqLi5k/f35FW1FREYsWLaJt27YVC1yzs7NJ\nS/vvf8Lu7u40bNiQVatWVZqCc/HiRdauXUtYWFjFvPcOHTrQqFEjZs+eXendX331FQ4ODnTr1u1O\nfkQRuQsaOdlRVHL97SXPFFR/nYuIiIilM9sc+MjISBISEpg8eTK5ubkEBQWxePFisrOzefPNNyvu\nmzBhAklJSaSmpgJgZWXFI488wpQpUxg2bBiDBg2irKyMBQsWcPLkSSZMmFDR197enmeeeYZXX32V\n3/3ud3Tp0oUdO3bw9ddf89xzz9GwYcO7/rlFpOa5N7S7brFuABZtSKN32wBcnKq/5kVERMQSma2A\nB3j77beZMmUKS5cu5dy5c5hMJqZNm0Z0dPRN+z3xxBMEBAQwc+ZMPvzwQ4qKijCZTHzwwQf06dOn\n0r0jR47ExsaGzz77jMTERHx9fZk4cSJjxoy5kx9NRO6iB7o3Ycb3hyqNxFtbGfD3dGLZ5p9Yvi2d\nDi186BsbSICn+XaSEhERqQmG8qsTxqVKtAuNXKWcWJYtB05edxeanLOXWLk9g017T1BUUkarxm7E\nxwbRItj1mu0n5c7Qz4plUl4sj3JimSxxFxoV8NWkAl6uUk4s043ycuFyMWt3ZZGYnEnBxSICvZyI\njw0ktrk31lZmWw5UL+hnxTIpL5ZHObFMlljAm3UKjYjI3eLUwIaBnUJIiA1k64EcVmzP4JNvU1iw\nLo0+7QLp3sZPJ7uKiEitoAJeROoVG2srukb60SXCl31H81iRlM78dWl8vfk4XSN86dsuEI9GDcwd\npoiIyA1Vu4D/6aef+Omnnyptwbhnzx6mTp1Kfn4+999/P8OGDavRIEVEaprBYCCiiTsRTdxJzznP\niqR01u78eYpNO5MX8bFBNPbTTlUiImJ5ql3AT548mfz8/IoCPi8vj3HjxnHp0iXs7Ox45ZVXcHd3\nJy4ursaDFRG5E4K8nRk3sCUPdm9CYnIm63Zns/3QKcICXIiPDSKymQdGLXgVERELUe2VW/v376dT\np04VXy9btowLFy6waNEitmzZQmRkJDNmzKjRIEVE7ga3hvYM6dmUyU92YnjvZpwpKOT9RfuYOH0b\na3dlUVh87QnQIiIid1u1C/i8vDy8vLwqvt64cSNt27YlLCwMW1tb+vfvX+nkVBGR2qaBnTV9YwL5\n2/gOjL+3JQ52VnyxIpU/frSZJRuPUnCxyNwhiohIPVbtKTQNGjTg/Pmft9IpLS0lOTmZ0aNHV1y3\nt7fnwoULNRehiIiZWBmNxDb3Jibci8MZ+axIyuCbTcf5bms6nVp50zcmCD8PR3OHKSIi9Uy1C/hm\nzZqxZMkS7r33XpYvX86lS5fo3LlzxfWsrCzc3NxqNEgREXMyGAyYglwxBbly4sxFVm3PYNP+k2zY\nc4KIJu7ExwYRHtRIB0OJiMhdUe0C/tFHH+XJJ5+smAffvHlz2rVrV3F906ZNtGjRouYiFBGxIL7u\njoxJCOe+bo1ZtzOLxJ2Z/P2rXQR7OxMfG0i7cC8dDCUiIndUtQv4Hj16MGPGDBITE3FycmLUqFEV\no05nz57Fx8eH++67r8YDFRGxJA0dbBnUJZSE9kFsOXCSFUkZTPvmIAvWpxEXHUi3SD8c7HXUhoiI\n1DxDeXl5ubmDqE3OnLlAWdnd/5bpeGXLo5xYJnPlpay8nL1pZ1iZlM6h9Hzsba3oFulHn3aBuLvY\n3/V4LIl+ViyT8mJ5lBPLZI68GI0G3N2dbni9RoaHSkpKSExM5Ny5c/Ts2RNPT8+aeKyISK1hNBho\n09SDNk09OH6ygBVJGazekcnqHZnENPciPjaQEB8dDCUiIr9etQv4t99+m23btrFw4UIAysvL+c1v\nfsOOHTsoLy+nUaNGzJs3j6CgoBoPVkSkNgjxacjjg1oyuHsTVidnsH53NtsO5hAe1Ii+sUFENHHX\nwVAiInLbqr3SauPGjZUWra5Zs4bt27fz6KOP8s477wAwbdq0motQRKSWcnexZ1ivZkx+sjNDezYl\n5+xl3luwl0mfbGP97iyKS3QwlIiIVF+1R+BPnjxJcHBwxddr164lICCA5557DoAjR47wzTff1FyE\nIiK1nIO9NQntg4hrF8COQ6dYkZTBjOWpLN5wlF5tA+jZ1h9nB1tzhykiIrVEtQv44uJirK3/223b\ntm0VW0oCBAYGkpubWzPRiYjUIdZWRjq09KF9C28OpeezIimdJT8cY9nWn+jcyoc+MYH4uutgKBER\nublqF/A+Pj7s2rWLoUOHcuTIETIyMnjmmWcqrp85cwYHB4caDVJEpC4xGAw0D3alebAr2acvsnJ7\nOj/sO8n63dlENvUgPjaQsEAdDCUiItdX7QL+nnvu4aOPPiIvL48jR47g5ORE9+7dK66npKRoAauI\nSBX5eTgytl9z7u/WhDXJmazdlcXu2acJ9XUmPjaIaJMnVkYdDCUiIv9V7QL+8ccf58SJExUHOb31\n1ls0bPjz1mjnz59nzZo1jB07tqbjFBGp01wcbbm/W2P6dwxm8/6TrExK5+OlB3BvaE+fmEC6RvjS\nwE4HQ4mISA0f5FRWVsbFixext7fHxsamph5rUXSQk1ylnFimupKXsvJy9hw5zfKkdI5knqOBnTU9\n2vjROzoAt4a162CoupKTukZ5sTzKiWWqswc5/fdlRpydnWvykSIi9ZLRYCAqzJOoME+OZhewIimd\n5UnprNyeQWxzL+Jjgwjy1r+3IiL10W0V8JcuXeKTTz5h1apVZGZmAhAQEEDfvn159NFHtYhVRKQG\nNfZryBP3tSI3/zKrdmSwcc8JthzIoXmwKwntg2gV6qYFryIi9Ui1p9Dk5+czcuRI0tLScHNzIyQk\nBIDjx4+Tl5dHkyZNmDVrFo0aNboT8ZqdptDIVcqJZaoPebl0pZj1u7NZtSOD/AtF+Hs40jcmkA4t\nfbCxtrwFr/UhJ7WR8mJ5lBPLVCem0Lz33nscPXqUSZMmMXz4cKysrAAoLS1l7ty5vP7663zwwQe8\n9NJLtx+1iIjckIO9Df06BNMnJpCklBxWJGXw7+8PsWjDUXpFB9Azyh+nBnVzHZKIiNxGAb9mzRqG\nDBnCyJEjK7VbWVnx0EMPkZKSwurVq1XAi4jcYdZWRjq18qVjSx8O/nSWFUnpLN5wlGVbjtOltS99\nYgLxdtWURhGRuqbaBfzp06dp3rz5Da+3aNGCxYsX/6qgRESk6gwGAy1D3GgZ4kZm7gVWJmWwYU82\na3dmERXmSUJsEE0DXMwdpoiI1JBqF/AeHh6kpKTc8HpKSgoeHh6/KigREbk9AZ5OPHJPcx7o3pjE\n5EzW7cpi5+Fcmvg1JD42iLZhnhiNWvAqIlKbVXu1U8+ePVmwYAFz5syhrKysor2srIy5c+eycOFC\nevXqVaNBiohI9TRysuPB7k2Y/GRnRvYJo+BSER8t2c8L07awekcGV4pKzB2iiIjcpmrvQnP27FmG\nDx9Oeno6bm5uhIaGAnDs2DHy8vIICgpizpw5uLq63pGAzU270MhVyollUl6ur6ysnF1HclmelE5a\nVgGO9tb0iPKnd3QAjZzs7ui7lRPLpLxYHuXEMtWJXWhcXV1ZuHAh06dPZ/Xq1ezbtw+AwMBABg8e\nzLhx43ByuvELRUTk7jMaDUSbvIg2efFj1jlWJKXz3dafWL4tnQ4tvYmPCSLAS/92i4jUBtUegb+V\nOXPmMHPmTL777ruafKzF0Ai8XKWcWCblpepOnb3Equ2ZbNyXTVFxGS1D3UiIDaJFiGuNHgylnFgm\n5cXyKCeWqU6MwN/K2bNnOXbsWE0/VkREapiXqwMj+4Zxb9dQ1u3KIjE5k3fm7ibA04n42EDat/DG\n2sryDoYSEanvaryAr46ioiL++c9/snTpUgoKCggPD+fZZ5+lY8eON+3Xq1cvsrKyrnstODiYlStX\nVnxtMpmue98rr7zCiBEjbj94EZE6wqmBDQM6hRAfG8S2gzms2J7Op8tSWLg+jd7RAfSI8sfRXgdD\niYhYCrMW8M8//zwrV65kzJgxBAcHs3jxYsaNG8cXX3xBVFTUDfu9+OKLXLx4sVJbdnY2U6ZMoXPn\nztfc36VLFwYNGlSpLTIysmY+hIhIHWFjbaRLhC+dW/tw4FgeK5LSWbj+KN9u/omuET8fDOXZqIG5\nwxQRqffMVsDv3buXZcuW8cILLzB27FgA7rvvPgYMGMDkyZOZNWvWDfvGxcVd0/bRRx8BMHDgwGuu\nNW7cmHvvvbdmAhcRqeMMBgOtGrvTqrE76TnnWbk9g7W7skjcmUl0mCfx7YNo4qeDoUREzMVskxuX\nL1+OjY0NQ4YMqWizs7Nj8ODBJCcnc+rUqWo979tvvyUgIIC2bdte9/qVK1coLCz8VTGLiNQ3Qd7O\nPDagBW8/0YmE9kEcOH6Wv85M5o0vk0lOzTXLon4RkfquSiPw//73v6v8wJ07d1bpvpSUFEJDQ3F0\ndKzUHhERQXl5OSkpKXh5eVXpWQcPHiQtLY3x48df9/qCBQv44osvKC8vJywsjGeeeYY+ffpU6dki\nIgKuznYM6dGUAR1D+GHvCVbtyODDxfvwcm1A35hAOrf2xc7GytxhiojUC1Uq4N96661qPbQq24/l\n5ubi7e19TbunpydAtUbgv/nmG4Br5rkDREVF0b9/fwICAjhx4gQzZ87kqaee4p133mHAgAFVfoeI\niEADO2v6xATSK9qfnYdPs3xbOl+uPMySjccqDoZycbQ1d5giInValfaBT0pKqvaDY2Njb3o9Li6O\npk2b8vHHH1dqz8jIIC4ujkmTJjFq1KhbvqesrIwePXrg7u7O4sWLb3n/pUuXGDBgAKWlpaxbt65G\n9zoWEalvysvLOXgsjyXrf2TbgZNYGY30jA7gvu5NCPJpaO7wRETqpCqNwN+qGL8d9vb2FBcXX9N+\ndZ66nV3VjvZOSkoiJyenYiHsrTg4ODB8+HDeeecdjh49SpMmTaocM+ggJ/kv5cQyKS93n5ezLb8d\n0IJ7O4WwcnsG63dmsiopndaN3UmIDaRruyBOn75g7jDlF/SzYnmUE8tULw5yqipPT8/rTpPJzc0F\nqPL892+++Qaj0cg999xT5Xf7+voCcO7cuSr3ERGRm/N2c2B0vIn7uoaydlcWa5Iz+fuc3SzccIze\n0f7EhHvpYCgRkRpgtn9Jw8PDOXbs2DX7ue/Zs6fi+q0UFRWxcuVKYmNjrzuf/kYyMjIAcHNzq0bE\nIiJSFc4OtgzqHMrfn+zE2H7hFJeWMv2bg0z4eAvfb/uJS1dKzB2iiEitZrYCPiEhgeLiYubPn1/R\nVlRUxKJFi2jbtm1FQZ6dnU1aWtp1n7F+/XoKCgquu/c7QF5e3jVtZ8+eZfbs2QQEBBASEvLrP4iI\niFyXjbUV3SL9+OC5Xvx+SATerg2YvzaN//toE3MSj3D63GVzhygiUiuZbQpNZGQkCQkJTJ48mdzc\nXIKCgli8eDHZ2dm8+eabFfdNmDCBpKQkUlNTr3nGN998g62tLfHx8dd9x6xZs0hMTKRHjx74+fmR\nk5PD3LlzycvL48MPP7xjn01ERP7LaDQQ0cSDiCYe/HTyPCu2p7N6Ryard2TSLtyT+NggQn214FVE\npKrMVsADvP3220yZMoWlS5dy7tw5TCYT06ZNIzo6+pZ9L1y4wLp16+jRowfOzs7XvScqKoqdO3cy\nf/58zp07h4ODA23atOHxxx+v0jtERKRmBfs489uBLRncvQmrd2Syfk8WSSmnCAtsREJsEBFN3TFq\ndzARkZuq0jaS8l/ahUauUk4sk/JieW6Wk8uFJWzYk83qHRmcKSjEx82BvjGBdGrlg60Ohrqj9LNi\neZQTy6RdaERERP5HAztr4mOD6B0dwI7UU6xIymDmilQWbThKr7b+9GobQEMdDCUiUokKeBERMTtr\nKyMdWvjQvrk3hzPyWb4tna83Hee7rel0bu1D35hAfN0dzR2miIhFUAEvIiIWw2AwYApyxRTkyokz\nF1m5PYNN+06yfnc2bZp6EB8bSFhgI52iLSL1mgp4ERGxSL7ujjycEM79XRuzZmcma3ZmsXv2aYJ9\nnEmIDaJduCdWRh0MJSL1jwp4ERGxaA0dbbmva2P6dwhm8/6TrNiewb++PsCCdXbEtQukW6QfDez0\n35mI1B/6F09ERGoFWxsrekT5062NH3t/PMPypHTmrvmRrzcdo3ukP3HtAnBraG/uMEVE7jgV8CIi\nUqsYDQbaNPOgTTMPjp0oYEVSOiu3Z7BqRwYxzb2Ijwki2Of654OIiNQFKuBFRKTWCvVtyPh7W3G6\nx+X/HAyVzdYDOYQHNSKhfRCtGutgKBGpe1TAi4hIrefh0oDhvZsxqHMI6/dks3pHJlPm78XX3YH4\n2CA6tvTGxloHQ4lI3aACXkRE6gwHexv6tQ+mT7tAtqecYkVSOp9/f4hF69PoFR1Azyh/nB10MJSI\n1G4q4EVEpM6xtjLSsZUPHVp6c+insyxPymDJxmN8t+UnOrf2pW9MIN5uDuYOU0TktqiAFxGROstg\nMNA8xI3mIW5knb7IyqR0Nu7NZt2uLNo08yA+NohmAS46GEpEahUV8CIiUi/4ezjym/7NeaBbYxJ3\nZrF2Zya7jpymsV9D4mODaBvmoYOhRKRWUAEvIiL1iouTHQ90a8w9HYLZtP8EK7dnMHXJfjxc7OnT\nLpAuEb46GEpELJr+hRIRkXrJztaKXm0D6NHGn90/nmZ5UjpfJR5h6Q/H6B7lR1x0IK7OduYOU0Tk\nGirgRUSkXjMaDbQN86RtmCdpWedYkZTO8m3prEzKoH0Lb+Jjgwj0cjJ3mCIiFVTAi4iI/EcTfxee\nvL81p/Ivs3p7Bhv3nmDz/pO0DHElPjaIlqFuWvAqImanAl5EROQXvBo14KE+YdzbNZR1u7JYnZzJ\nP+btwd/TkfiYINq38MbGWgteRcQ8VMCLiIjcgKO9Dfd0DCE+NohtB3NYkZTOZ9+lsHB9Gr2jA+gR\n5Y9TAxtzhyki9YwKeBERkVuwtjLSubUvnVr5cOB4HiuSMli04SjfbjlO19Z+9IkJwMtVB0OJyN2h\nAl5ERKSKDAYDrULdaRXqTuapC6zYns663Vms2ZVJ2zBP4mODaOrvYu4wRaSOUwEvIiJyGwK8nHj0\nnhY80K0Ja3ZmsnZnFsmpuTT1dyE+NpCoZp4YjVrwKiI1TwW8iIjIr+DqbMeD3ZtwT8dgftj788FQ\nHy7ej1ejBvSJCaRLa1/sbK3MHaaI1CEq4EVERGqAva01ce0C6dU2gJ2Hc1mRlM6sVYdZsvEoPaL8\n6R0dQCMnHQwlIr+eCngREZEaZDQaaBfuRbtwL37MPMfypHS+2/ITK5LS6dDCh76xgQR46mAoEbl9\nKuBFRETukKYBLjwV0Jqcs5dYuT2DTXtP8MO+E7Rq7EZ8bBAtgl11MJSIVJsKeBERkTvM29WB0X1N\n3N+1MWt3ZZGYnMk7c3YT6OVEfGwgsc29sbbSwVAiUjUq4EVERO4SpwY2DOwUQkJsIFsP5LBiewaf\nfJvCgnVp9GkXSPc2fjjY62AoEbk5FfAiIiJ3mY21FV0j/egS4cv+Y3ks35bO/HVpfL35OF0jfOnb\nLhCPRg3MHaaIWCgV8CIiImZiMBho3did1o3dSc85z4qkdNbu/HmKTTuTF/GxQTT2a2juMEXEwqiA\nFxERsQBB3s6MG9iSB7s3ITE5k3W7s9l+6BRhAS7ExwYR2cwDoxa8iggq4EVERCyKW0N7hvRsyoBO\nIWzce4JV2zN4f9E+vF0b0Dc2iE6tfLCz0cFQIvWZCngREREL1MDOmr4xgfSO9ic59eeDob5Ykcri\nDUfpGeVPr+gAXBxtzR2miJiBWQv4oqIi/vnPf7J06VIKCgoIDw/n2WefpWPHjjft16tXL7Kysq57\nLTg4mJUrV1Zqmz9/Pp999hmZmZn4+fkxZswYRo4cWWOfQ0RE5E6xMhqJbe5NzP9v787jo6rv/Y+/\nZpLJQiAJSSbLAAkhkIWQTEIUCEtAIDVVFLUgZXVpuXpdbpWrF6m3jz5qb/U+1CoU662A1kKpCMoi\nUAFZJOwIyIQlgITdySYYkhCylMzvD3+ZhzEJsiSZCXk//zLf8/3O+Rw+OZ5PvvM958SHcuxsCWt3\nn2XV9lN8uusMA/uE8ZPbI7GE+Lk6TBFpRS4t4F944QXWrVvHlClTiIqKYtmyZUydOpUFCxaQmpra\n5Lhf//rXXLp0qV6b3W5n5syZDBo0qF77okWL+O1vf0tWVhaPPPIIe/bs4aWXXqKqqopHH320RY5L\nRESkuRkMBuIiOxMXGAgplgAAIABJREFU2Zn885f47IuzbDtYQLYtn+SYYO7sF0l8ZKBeDCXSDhgc\nDofDFTvOyclh7NixzJgxg4cffhiAqqoqRo0aRWhoKAsXLryuz3v77beZNWsWH3zwAX379gWgsrKS\noUOHkpaWxttvv+3s+9xzz7Fx40Y2b95Mp06drms/58+XU1vb+v9kZnMniovLWn2/0jTlxD0pL+5H\nOWk5pRXVfL7vazbsO0dZRQ1RYZ24s183bosP/dEXQykv7kc5cU+uyIvRaCA4uGPT21sxlnrWrFmD\nyWRi7NixzjZvb2/GjBnD3r17KSoquq7PW7VqFV27dnUW7wC7du2ipKSECRMm1Os7ceJELl26RHZ2\n9s0dhIiIiAv5d/Di3sHRvPbvA3koK47qf11hzsrDvPDODtbsOkNF5b9cHaKItACXFfC5ublER0fj\n51d/3V5ycjIOh4Pc3Nxr/qzDhw+Tl5fHqFGjGrQD9OnTp157YmIiRqPRuV1ERKQt8zJ5MDSlC7//\nZX/+Y0wyoYG+LN50nOfe3saiDV9x/mKlq0MUkWbksjXwxcXFhIWFNWg3m80A1zUDv3LlSgDuvffe\nBvvw8vIiMDCwXntd2/XO8ouIiLgzo8FASs8QUnqGcKqglLW7z7J+zznW7znH7Qmh3NmvG/nnK1i6\nOY8LpVUE+XvzwNAY0hPDXR26iFwHlxXwlZWVmEymBu3e3t7Ad+vhr0VtbS2rV6+md+/exMTEXNM+\n6vZzrfv4vqutR2ppZvP1rdeXlqecuCflxf0oJ63PbO7E7UldKPq2gpVbTrB252l2HS7EYIC6u9/O\nl1Yxf81R/Dv5MCytm2sDFkDnirtyt7y4rID38fGhpqamQXtdUV1XyP+Y3bt3U1hY6LwR9of7qK6u\nbnRcVVXVNe/j+3QTq9RRTtyT8uJ+lBPXMgD3pkcxMrUL//V/26moqr8uvqrmCu+vOkRiZGDjHyCt\nRueKe9JNrN9jNpsbXcJSXFwMQGho6DV9zsqVKzEajdx9992N7qOmpoaSkpJ67dXV1ZSUlFzzPkRE\nRNq6Dj6eDYr3OudLq9j/1Tdcqa1t5ahE5Ea4rICPj4/n5MmTDZ7nbrPZnNt/THV1NevWraNfv36N\nrqdPSEgA4ODBg/XaDx48SG1trXO7iIhIexDs3/g3zwYD/OnjHJ5/eztLs09QXHK5lSMTkevhsgI+\nKyuLmpoalixZ4myrrq5m6dKl9O3b11mQ2+128vLyGv2MzZs3U1payj333NPo9gEDBhAYGMg//vGP\neu0ffPABHTp0ICMjo5mORkRExP09MDQGL8/6l34vTyOP3pXAUw8kERnWidU7TvHCX3bwx0Vf8sWR\nIv51RbPyIu7GZWvgrVYrWVlZvP766xQXFxMZGcmyZcuw2+288sorzn7Tp09n9+7dHD16tMFnrFy5\nEi8vL+68885G9+Hj48N//Md/8NJLL/GrX/2KwYMHs2fPHj755BOee+45/P39W+z4RERE3E3d02aa\negpN31gzF0or2ZKTz5YcO/+3/CAdfU0MSgonw2ohItjvah8vIq3EZQU8wKuvvsrMmTNZsWIFFy9e\nJC4ujjlz5pCWlvajY8vLy/n8888ZNmzYVd+mOnHiREwmE++99x4bNmwgIiKCF198kSlTpjTnoYiI\niLQJ6YnhpCeGN3ljXpC/D6MHR3PPwO4cOnWB7P121u85x9rdZ4ntGkBGioXb4kLxMnm4IHoRATA4\nHI7Wf6RKG6an0Egd5cQ9KS/uRzlxT9eTl4uXqtl+IJ/NNjtF317G19uT9MQwMqwWIsPc6/F6bZnO\nFffkjk+hcekMvIiIiLi/AD8vfjogiqz+kRw9U0K2zU62LZ+N+76me3gnMlIs9E8Iw9dbZYVIa9CZ\nJiIiItfEYDAQH9WZ+KjOTLhcw45DBWTb7Mxfc5QPNxynX0IoGSkWekT4YzAYXB2uyC1LBbyIiIhc\nt46+JjJv68bItK6csJeSbbOzO7eILTn5dDH7kWG1kJ4YTkffxt+ILiI3TgW8iIiI3DCDwUBMlwBi\nugTw8xG92JVbSPZ+Ox+s/4olm/K4Ld5MRrKFuMhAzcqLNBMV8CIiItIsfL09GZbShWEpXThTWEa2\nzc6OQ4XsPFRIWGdfMqwWBiZFEODn5epQRdo0FfAiIiLS7CLDOjHpJ3GMvaMne44UscVmZ8nneSzN\nPkFKzxAyUiwkdg/CaNSsvMj1UgEvIiIiLcbb5MGgpAgGJUWQf/4S2TY72w4UsPdYMcH+3gxOtjAk\nOYIgfx9XhyrSZqiAFxERkVYREezHuOG9eCAjhv3HvyF7/9es2HqST7adJKlHMBlWC8kxwXh6GF0d\nqohbUwEvIiIircrkaeT2+FBujw+luOQyW3LsbM3J562lBwjw82JQUgQZ1ghCO3dwdagibkkFvIiI\niLiMOdCXBzJiGD04mgN5F8i22fl012n+ufM0CVGdGWKNIC3WjMnTw9WhirgNFfAiIiLich5GIym9\nQkjpFcK3ZVVsPZDPFpudOZ8cxs/Hk4F9IshIsdAlxM/VoYq4nAp4ERERcSudO3lzz8Du3J0eRe6p\nb9lss7Nx3zk+23OWnl0CGGKNoF98GN5empWX9kkFvIiIiLglo8FAYnQQidFBlFZUs/1AAdk2O3/9\n5xEWbfiK/r3DybBG0D3c39WhirQqFfAiIiLi9vw7eJHVP5I7+3Xjq3MX///jKPP5/MuviQzryFCr\nhf69w+ngo9JGbn36LRcREZE2w2AwENstkNhugUwY2YsdhwrJttlZsO4YH248zu3xoWSkWOjZJQCD\nQS+JkluTCngRERFpkzr4mBiR1pXhfbtwqqCMbJudnYcL2XawAEuIHxnJEaT3CadTBy9XhyrSrFTA\ni4iISJtmMBiIjvAnOsKfccN7sju3iC02O4s2HuejzXn0jTWTYbUQH9UZo2bl5RagAl5ERERuGT5e\nnmRYLWRYLZwrKifbZmfHoQJ25xZhDvQhw2phUFIEgR29XR2qyA1TAS8iIiK3pK6hHZmQGcvYO2LY\ne7SYbJudjzefYFn2Saw9g8mwWkjqEYzRqFl5aVtUwIuIiMgtzeTpwYDEcAYkhlN4ocL5BJsvv/qG\nzp28GZwUwRBrBCEBvq4OVeSaqIAXERGRdiMsqANj7+jJ/Rk9sB3/hs02O6u2n2LV9lMkRgeRYbWQ\n0isETw+jq0MVaZIKeBEREWl3PD2MpMWFkhYXyvmLlWzJsbMlJ5+3lx/Ev4OJgUkRZFgthAd1cHWo\nIg2ogBcREZF2LTjAh/uG9ODeQdEcPHmebFs+63afZc2uM8R1CyTDaiEtzoyXycPVoYoAKuBFRERE\nADAaDSTHhJAcE8LF8iq2Hshniy2fuasOs/AzT9L7hDPUaqFraEdXhyrtnAp4ERERkR8I6OjN3end\n+emAKI6e/pbsnHw27/+aDXvPER3hz9AUC/0SQvHxUiklrU+/dSIiIiJNMBoMJHQPIqF7EOWXY9l+\nsIBsm533Pz3CBxu+on9CKBnWLkRHdMKgl0RJK1EBLyIiInINOvqa+Mnt3ci8rSt59lKy99vZebiQ\nbFs+Xc0dGZpiYUBiGH4+JleHKrc4FfAiIiIi18FgMNCzSwA9uwQwfmQvdh0uZLPNzsLPjrF403Fu\nizOTYbUQ2y1Qs/LSIlTAi4iIiNwgX29PhqV2YVhqF04XlJFts7PzcAE7DhUSHtSBDKuFgX3C8ffz\ncnWocgtRAS8iIiLSDKLCOzE5PI4Hh/dkz5EiNtvsLN50nI8355HaK4SMFAu9uwdh1Ky83CQV8CIi\nIiLNyNvkwaCkCAYlRfD1N5fYYrOz/WABe44WE+zvwxBrBIOTIgjy93F1qNJGqYAXERERaSFdQvz4\n+Yhe/GxoDF9+Vczm/XaWbznJiq0nSe4RTEaKheSYYDyMRleHKm2ISwv46upqZs2axYoVKygtLSU+\nPp5nn32W9PT0axq/cuVK/va3v3H8+HG8vLyIjY3lv/7rv0hOTgbg3LlzjBgxotGxc+fOJSMjo9mO\nRURERKQpJk8j/RLC6JcQRlHJZbbY7Gw9kI/t4wMEdPRicFIE993RC73rVa6FSwv4F154gXXr1jFl\nyhSioqJYtmwZU6dOZcGCBaSmpl517Jtvvsm8efO49957GTduHBUVFRw5coTi4uIGfe+9914GDx5c\nry0+Pr5Zj0VERETkWoQG+vKzoTHcNySanOPn2Wyz88+dp1m94zQJUZ0ZmmIhtZcZk6dm5aVxLivg\nc3JyWL16NTNmzODhhx8G4L777mPUqFG8/vrrLFy4sMmx+/bt45133mH27NlkZmb+6L4SExMZPXp0\nc4UuIiIictM8jEZSY82kxpq5UFrJlycusGb7Kf6y4hAdfU0M7BNOhtWCJcTP1aGKm3FZAb9mzRpM\nJhNjx451tnl7ezNmzBjefPNNioqKCA0NbXTs/PnzSUpKIjMzk9raWi5fvoyf39V/uSsqKvD09MTL\nS49xEhEREfcS5O/DzzPjuMMaweFTF8jeb2fD3nOs++IsPbsGMNRq4bb4ULxNWmQj4LLvZnJzc4mO\njm5QeCcnJ+NwOMjNzW1y7I4dO0hKSuKNN94gLS2Nvn37Mnz4cD755JNG+8+aNYvU1FSSk5MZN24c\nX3zxRbMei4iIiEhzMBoM9IkO5on7k/jjk4MYe0cMZRU1vLs6l2lvbWPBuqOcLihzdZjiYi6bgS8u\nLiYsLKxBu9lsBqCoqKjRcRcvXqSkpITVq1fj4eHBc889R2BgIAsXLuT555/H19fXuazGaDQyePBg\nMjMzCQ0N5fTp07z77rs88sgjvP/++9x2220td4AiIiIiN8Hfz4uf9o8iq18kx86WkG2zszUnn037\nviYqvBNDrRb69w7D11sPFWxvDA6Hw+GKHY8cOZKePXvyl7/8pV772bNnGTlyJL/5zW+YNGlSg3H5\n+fkMGzYMgMWLF2O1WoHvnmiTmZlJ586dWb58eZP7LSws5O6776Znz54sWrSo+Q5IREREpIWVV1Tz\n+b5zrN15mlP5pXh7eTDE2oU7B0QRF9UZg14S1S647E82Hx8fampqGrRXVVUB362Hb0xde9euXZ3F\nO4CXlxd33nkn8+fP59KlS02uiQ8LC+Puu+9m8eLFXL58GV9f3+uK+/z5cmprW/9vHrO5E8XF+srM\nnSgn7kl5cT/KiXtSXtzPteakf5yZfrEhnMwvI9v2NVv2f836L87QJcSPIVYLA/uE09HX1AoRtw+u\nOFeMRgPBwR2b3O6yAt5sNje6TKbuMZBN3cAaGBiIl5cXISEhDbaFhITgcDgoLy+/6k2tERER1NbW\nUlpaet0FvIiIiIirGQwGelj86WHxZ9zwXnxxpIjN++0s2vAVH32eR1qcmQyrhbjIQIyalb/luKyA\nj4+PZ8GCBQ1my202m3N7Y4xGIwkJCRQWFjbYVlBQgIeHBwEBAVfd99mzZ6+pn4iIiIi78/X2JMNq\nIcNq4WxROdk2OzsOFrDrcCGhgb4MsUYwOCmCgI6Nr26QtsdlT6HJysqipqaGJUuWONuqq6tZunQp\nffv2dd7garfbycvLazA2Pz+fbdu2OdvKy8v59NNPSU1NxcfHB4ALFy402O/p06dZvXo1t912m7Of\niIiIyK2gW2hHJmbG8sZTg5g6qjeBnbz5ePMJnnt7O28tPUBO3jcuWQoszctlM/BWq5WsrCxef/11\niouLiYyMZNmyZdjtdl555RVnv+nTp7N7926OHj3qbBs/fjxLlizh6aef5uGHH8bf35+PP/6YsrIy\npk2b5uz32muvcfbsWQYMGEBoaChnzpxx3rg6ffr01jtYERERkVbkZfIgvU846X3CKbhQQbbNzrYD\n+ew7VkyQvzeDkyIYkmwhOECTmW2RS5879OqrrzJz5kxWrFjBxYsXiYuLY86cOaSlpV11nK+vL/Pn\nz+fVV1/l73//O5WVlSQmJvLXv/613thBgwaxaNEi/v73v1NWVoa/vz+DBg3iqaeeolevXi19eCIi\nIiIuFx7UgQfv6MkDGT3Y/9U3ZNvsrNx2ipXbTpHYI4ihVgvWniF4erhsYYZcJ5c9RrKt0lNopI5y\n4p6UF/ejnLgn5cX9tGZOvim5zJacfLYeyOfbsir8/bwYlBRORrKFsKAOrRJDW6Gn0IiIiIiIy4UE\n+nJ/Rg9GD47mwInzZNvsrN11lk93niE+MpAMq4W0ODMmTw9XhyqNUAEvIiIi0k4ZjQasPUOw9gzh\n27Iqth/MJ9tmZ87Kw/h95kl6YjgZKRa6mpueDZbWpwJeREREROjcyZu707vz0wFRHDn9Ldk2O5/v\n/5r1e88RY/Enw2rh9oRQfLxUPrqaMiAiIiIiTkaDgd7dg+jdPYiyimp2HCxgs83OXz89wgcbvqJ/\n7zAyrBa6h3fCoJdEuYQKeBERERFpVKcOXvykXySZt3fj+NcXnS+J2rzfTmRoR4ZYLaQnhtHBx+Tq\nUNsVFfAiIiIiclUGg4FeXQPp1TWQ8SNi2XX4u1n5hZ8dY8mm49wWH0qG1UKvrgGalW8FKuBFRERE\n5Jp18PHkjr5duaNvV04XlLHZZmfnoQK2HywgIrgDQ5ItDEwKx7+Dl6tDvWWpgBcRERGRGxIV3okp\n4XGMu6Mnu48UssWWz+JNx/l4cx59Y81kWC0kdO+MUbPyzUoFvIiIiIjcFG8vD4YkWxiSbOHr4nKy\nbflsP5jPF0eKCAnwYYjVwuCkCDp38nZ1qLcEFfAiIiIi0my6mDsyfmQvxgzrwb5j35Bts7Ms+wTL\nt5zAGhNChtVCUkwQHkajq0Nts1TAi4iIiEizM3l60L93GP17h1H4bQVbbPlsPZDP/uPfENjRi8HJ\nFoYkR2AO9HV1qG2OCngRERERaVFhnTswZlgM9w2JJifvPNk2O6t3nGL19lP07t6ZjJQupPYKwdND\ns/LXQgW8iIiIiLQKTw8jfWPN9I01c6G0kq05+WzJsfN/yw/S0dfEoKRwMqwWIoL9XB2qW1MBLyIi\nIiKtLsjfh3sHRzNqYHcOnbpAts3O+j3nWLv7LLFdA8hIsXBbXCheJg9Xh+p2VMCLiIiIiMsYjQaS\negST1COYi5eq2X4gn2ybnXmrcln42VekJ4aRYbUQGdbJ1aG6DRXwIiIiIuIWAvy8+OmAKLL6R3L0\nTAnZOXaybfls3Pc10RGdGGK10D8hDF/v9l3Ctu+jFxERERG3YzAYiI/qTHxUZyaMrGHHoQKybXbm\nrznKhxuO0y8hlIwUCz0i/DG0w5dEqYAXEREREbfV0ddE5m3dGJnWlRP5pWTvt7M7t4gtOfl0Nfsx\nxGohPTGcjr4mV4faalTAi4iIiIjbMxgMxFgCiLEE8PMRvdiVW8gWm50P1n/Fkk153BZvJiPZQlxk\n4C0/K68CXkRERETaFF9vT4aldGFYShfOFJaRbbOz41AhOw8VEtbZlwyrhYFJEQT4ebk61BahAl5E\nRERE2qzIsE5M+kkcD97Rkz1Hi8jeb2fJ53kszT5BSs8QMlIsJHYPwmi8dWblVcCLiIiISJvnZfJg\nYJ8IBvaJIP/8JbbY8tl6IJ+9x4oJ9vdmSLKFwckRBPn7uDrUm6YCXkRERERuKRHBfjw4vCcPDO3B\nl199Q/b+r1m+9SQrtp0kqUcwGVYLyTHBeHoYXR3qDVEBLyIiIiK3JE8PI7fHh3J7fCjFJZfZkpPP\n1hw7by09QICfF4OSIsiwRhDauYOrQ70uKuBFRERE5JZnDvTlgYwejB7cnQN5F8i22fl012n+ufM0\nCVGdybBa6BtrxuT53az8jkMFLN2cx4XSKoL8vXlgaAzpieEuPorvqIAXERERkXbDw2gkpVcIKb1C\n+Lasiq0H8tlis/POJ4fw8/FkYJ8IAjp68cnWk1T/qxaA86VV/O3TIwBuUcSrgBcRERGRdqlzJ2/u\nGdidu9OjyD39Ldn77Wzcd44rtY4Gfav/VcvSzXkq4EVEREREXM1oMJDYPYjE7kGUVlTzzJ+2Ntrv\nfGlVK0fWuLZ5662IiIiISAvw7+BFsL93o9uaam9tKuBFRERERL7ngaExeHnWL5O9PI08MDTGRRHV\npyU0IiIiIiLfU7fOXU+hERERERFpI9ITw0lPDMds7kRxcZmrw6lHS2hERERERNoQlxbw1dXVvPba\nawwePJjk5GQefPBBduzYcc3jV65cyZgxY0hJSaFfv35MmjSJnJycen1qa2uZO3cuw4cPJykpiXvu\nuYd//vOfzX0oIiIiIiKtwqVLaF544QXWrVvHlClTiIqKYtmyZUydOpUFCxaQmpp61bFvvvkm8+bN\n495772XcuHFUVFRw5MgRiouLG/SbM2cO48aNo0+fPmzYsIFnn30Wo9FIVlZWSx6eiIiIiEizMzgc\njoZPqm8FOTk5jB07lhkzZvDwww8DUFVVxahRowgNDWXhwoVNjt23bx8TJkxg9uzZZGZmNtmvsLCQ\nESNGMH78eF588UUAHA4HkyZNIj8/n/Xr12M0Xt+XEOfPl1PbyMP9W5o7rr9q75QT96S8uB/lxD0p\nL+5HOXFPrsiL0WggOLhj09tbMZZ61qxZg8lkYuzYsc42b29vxowZw969eykqKmpy7Pz580lKSiIz\nM5Pa2louXbrUaL/169dTU1PDhAkTnG0Gg4Hx48fz9ddfN1huIyIiIiLi7lxWwOfm5hIdHY2fn1+9\n9uTkZBwOB7m5uU2O3bFjB0lJSbzxxhukpaXRt29fhg8fzieffNJgHx07diQ6OrrBPgAOHz7cTEcj\nIiIiItI6XLYGvri4mLCwsAbtZrMZoMkZ+IsXL1JSUsLq1avx8PDgueeeIzAwkIULF/L888/j6+vr\nXFZTXFxMSEjIde9DRERERMRduayAr6ysxGQyNWj39v7uFbVVVVWNjquoqACgpKSExYsXY7VaAcjM\nzCQzM5M///nPzgK+srISLy+v697H1VxtPVJLM5s7uWzf0jjlxD0pL+5HOXFPyov7UU7ck7vlxWUF\nvI+PDzU1NQ3a64rquiL7h+rau3bt6izeAby8vLjzzjuZP38+ly5dws/PDx8fH6qrq697H1ejm1il\njnLinpQX96OcuCflxf0oJ+7JHW9idVkBbzabG13CUvcYyNDQ0EbHBQYG4uXl1ejSmJCQEBwOB+Xl\n5fj5+WE2m9mzZ8917+NqjEbDdY9pLq7ctzROOXFPyov7UU7ck/LifpQT99Taefmx/bmsgI+Pj2fB\nggXO2fI6NpvNub0xRqORhIQECgsLG2wrKCjAw8ODgIAAABISEliyZAknT56sdyNr3T4SEhKuO+7O\nnf1+vFMLceXyHWmccuKelBf3o5y4J+XF/Sgn7snd8uKyp9BkZWVRU1PDkiVLnG3V1dUsXbqUvn37\nOm9wtdvt5OXlNRibn5/Ptm3bnG3l5eV8+umnpKam4uPjA8CIESMwmUz84x//cPZzOBwsWrQIi8VS\nbwmOiIiIiEhb4LIZeKvVSlZWFq+//jrFxcVERkaybNky7HY7r7zyirPf9OnT2b17N0ePHnW2jR8/\nniVLlvD000/z8MMP4+/vz8cff0xZWRnTpk1z9gsPD2fKlCm89957VFVVkZSUxPr169mzZw9vvvnm\ndb/ESURERETE1Vz2Jlb47mbSmTNnsnLlSi5evEhcXBzTpk1j4MCBzj6TJ09uUMDDd+vYX331VTZv\n3kxlZSWJiYlMmzaN22+/vV6/2tpa5s6dy4cffkhRURHR0dE89thjjBo1qlWOUURERESkObm0gBcR\nERERkeujNSQiIiIiIm2ICngRERERkTZEBbyIiIiISBuiAl5EREREpA1RAS8iIiIi0oaogBcRERER\naUNc9iIn+e7Ns7NmzWLFihWUlpYSHx/Ps88+S3p6+o+OLSws5OWXX2bbtm3U1tYyYMAAZsyYQbdu\n3Voh8lvXjeZk9uzZvPXWWw3aQ0JC6r0xWK5fUVER8+fPx2azcfDgQSoqKpg/fz79+/e/pvF5eXm8\n/PLL7Nu3D5PJxB133MH06dMJCgpq4chvbTeTlxdeeIFly5Y1aLdarSxevLglwm0XcnJyWLZsGbt2\n7cJutxMYGEhqairPPPMMUVFRPzpe15XmdzM50XWl5Rw4cIC//OUvHD58mPPnz9OpUyfi4+N58skn\n6du374+Od4dzRQW8C73wwgusW7eOKVOmEBUVxbJly5g6dSoLFiwgNTW1yXGXLl1iypQpXLp0iccf\nfxxPT0/ef/99pkyZwvLlywkICGjFo7i13GhO6rz00kv4+Pg4f/7+f8uNOXnyJHPnziUqKoq4uDi+\n/PLLax5bUFDAxIkT8ff359lnn6WiooL33nuPY8eOsXjxYkwmUwtGfmu7mbwA+Pr68rvf/a5em/6o\nujnz5s1j3759ZGVlERcXR3FxMQsXLuS+++7jo48+IiYmpsmxuq60jJvJSR1dV5rf2bNnuXLlCmPH\njsVsNlNWVsbKlSuZNGkSc+fOZdCgQU2OdZtzxSEuYbPZHLGxsY6//vWvzrbKykrHyJEjHRMmTLjq\n2Dlz5jji4uIchw4dcrYdP37ckZCQ4Jg5c2ZLhXzLu5mc/OlPf3LExsY6Ll682MJRtj9lZWWOCxcu\nOBwOh+Ozzz5zxMbGOnbu3HlNY3/72986UlJSHAUFBc62bdu2OWJjYx1LlixpkXjbi5vJy/Tp0x1p\naWktGV67tHfvXkdVVVW9tpMnTzr69OnjmD59+lXH6rrSMm4mJ7qutK6KigrHwIEDHf/2b/921X7u\ncq5oDbyLrFmzBpPJxNixY51t3t7ejBkzhr1791JUVNTk2LVr15KSkkLv3r2dbTExMaSnp/Ppp5+2\naNy3spvJSR2Hw0F5eTkOveC42XTs2JHOnTvf0Nh169YxfPhwwsLCnG0DBw6ke/fuOldu0s3kpc6V\nK1coLy9vpoikb9++eHl51Wvr3r07vXr1Ii8v76pjdV1pGTeTkzq6rrQOX19fgoKCKC0tvWo/dzlX\nVMC7SG5uLtHQaJCtAAALOElEQVTR0fj5+dVrT05OxuFwkJub2+i42tpajh49Sp8+fRpsS0pK4tSp\nU1y+fLlFYr7V3WhOvm/YsGGkpaWRlpbGjBkzKCkpaalw5UcUFhZy/vz5Rs+V5OTka8qntJxLly45\nz5X+/fvzyiuvUFVV5eqwbjkOh4Nvvvnmqn9s6brSuq4lJ9+n60rLKS8v58KFC5w4cYI33niDY8eO\nXfWeN3c6V7QG3kWKi4vrzQrWMZvNAE3O9paUlFBdXe3s98OxDoeD4uJiIiMjmzfgduBGcwLg7+/P\n5MmTsVqtmEwmdu7cyYcffsjhw4dZsmRJgxkYaXl1+WrqXDl//jxXrlzBw8OjtUNr98xmM7/85S9J\nSEigtraWTZs28f7775OXl8e8efNcHd4t5ZNPPqGwsJBnn322yT66rrSua8kJ6LrSGn7961+zdu1a\nAEwmEz//+c95/PHHm+zvTueKCngXqaysbPQGOm9vb4AmZ6Lq2hs7cevGVlZWNleY7cqN5gTgoYce\nqvdzVlYWvXr14qWXXmL58uU8+OCDzRus/KhrPVd++I2LtLz//M//rPfzqFGjCAsL491332Xbtm1X\nvYFMrl1eXh4vvfQSaWlpjB49usl+uq60nmvNCei60hqefPJJxo0bR0FBAStWrKC6upqampom/zhy\np3NFS2hcxMfHh5qamgbtdb8cdb8IP1TXXl1d3eRY3aF+Y240J00ZP348vr6+7Nixo1nik+ujc6Vt\nefTRRwF0vjST4uJiHnvsMQICApg1axZGY9OXe50rreN6ctIUXVeaV1xcHIMGDeJnP/sZ7777LocO\nHWLGjBlN9nenc0UFvIuYzeZGl2QUFxcDEBoa2ui4wMBAvLy8nP1+ONZgMDT61Y78uBvNSVOMRiNh\nYWFcvHixWeKT61OXr6bOleDgYC2fcSMhISGYTCadL82grKyMqVOnUlZWxrx58370mqDrSsu73pw0\nRdeVlmMymRgxYgTr1q1rchbdnc4VFfAuEh8fz8mTJ7l06VK9dpvN5tzeGKPRSGxsLAcPHmywLScn\nh6ioKHx9fZs/4HbgRnPSlJqaGvLz82/6SR1yY8LCwggKCmryXElISHBBVNKUgoICampq9Cz4m1RV\nVcXjjz/OqVOneOedd+jRo8ePjtF1pWXdSE6aoutKy6qsrMThcDSoA+q407miAt5FsrKyqKmpYcmS\nJc626upqli5dSt++fZ03U9rt9gaPmrrzzjvZv38/hw8fdradOHGCnTt3kpWV1ToHcAu6mZxcuHCh\nwee9++67VFVVMWTIkJYNXAA4c+YMZ86cqdf2k5/8hI0bN1JYWOhs27FjB6dOndK50kp+mJeqqqpG\nHx359ttvAzB48OBWi+1Wc+XKFZ555hn279/PrFmzSElJabSfriut52ZyoutKy2ns37a8vJy1a9cS\nERFBcHAw4N7nisGhB4u6zK9+9Ss2bNjAQw89RGRkJMuWLePgwYP87W9/Iy0tDYDJkyeze/dujh49\n6hxXXl7O/fffz+XLl3nkkUfw8PDg/fffx+FwsHz5cv1lfhNuNCdWq5W77rqL2NhYvLy82LVrF2vX\nriUtLY358+fj6an7xW9GXXGXl5fHqlWr+NnPfkbXrl3x9/dn0qRJAAwfPhyAjRs3Osfl5+dz3333\nERgYyKRJk6ioqODdd98lIiJCT3FoBjeSl3PnznH//fczatQoevTo4XwKzY4dO7jrrrt48803XXMw\nt4A//OEPzJ8/nzvuuIOf/vSn9bb5+fkxcuRIQNeV1nQzOdF1peVMmTIFb29vUlNTMZvN5Ofns3Tp\nUgoKCnjjjTe46667APc+V1TAu1BVVRUzZ85k5cqVXLx4kbi4OKZNm8bAgQOdfRr75YHvvm5++eWX\n2bZtG7W1tfTv358XX3yRbt26tfZh3FJuNCf//d//zb59+8jPz6empoYuXbpw11138dhjj+nmr2YQ\nFxfXaHuXLl2chWFjBTzAV199xf/+7/+yd+9eTCYTw4YNY8aMGVqq0QxuJC+lpaX8/ve/x2azUVRU\nRG1tLd27d+f+++9nypQpui/hJtT9v6kx38+Jriut52ZyoutKy/noo49YsWIFx48fp7S0lE6dOpGS\nksKjjz5Kv379nP3c+VxRAS8iIiIi0oZoDbyIiIiISBuiAl5EREREpA1RAS8iIiIi0oaogBcRERER\naUNUwIuIiIiItCEq4EVERERE2hAV8CIiIiIibYgKeBERcXuTJ092vhRKRKS903t4RUTaqV27djFl\nypQmt3t4eHD48OFWjEhERK6FCngRkXZu1KhRZGRkNGg3GvUlrYiIO1IBLyLSzvXu3ZvRo0e7OgwR\nEblGml4REZGrOnfuHHFxccyePZtVq1Zxzz33kJSUxLBhw5g9ezb/+te/Gow5cuQITz75JP379ycp\nKYm77rqLuXPncuXKlQZ9i4uL+Z//+R9GjBhBnz59SE9P55FHHmHbtm0N+hYWFjJt2jRuv/12rFYr\nv/jFLzh58mSLHLeIiLvSDLyISDt3+fJlLly40KDdy8uLjh07On/euHEjZ8+eZeLEiYSEhLBx40be\neust7HY7r7zyirPfgQMHmDx5Mp6ens6+mzZt4vXXX+fIkSP88Y9/dPY9d+4c48eP5/z584wePZo+\nffpw+fJlbDYb27dvZ9CgQc6+FRUVTJo0CavVyrPPPsu5c+eYP38+TzzxBKtWrcLDw6OF/oVERNyL\nCngRkXZu9uzZzJ49u0H7sGHDeOedd5w/HzlyhI8++ojExEQAJk2axFNPPcXSpUsZN24cKSkpAPzh\nD3+gurqaRYsWER8f7+z7zDPPsGrVKsaMGUN6ejoAv/vd7ygqKmLevHkMGTKk3v5ra2vr/fztt9/y\ni1/8gqlTpzrbgoKCeO2119i+fXuD8SIityoV8CIi7dy4cePIyspq0B4UFFTv54EDBzqLdwCDwcAv\nf/lL1q9fz2effUZKSgrnz5/nyy+/JDMz01m81/X993//d9asWcNnn31Geno6JSUlbNmyhSFDhjRa\nfP/wJlqj0djgqTkDBgwA4PTp0yrgRaTdUAEvItLORUVFMXDgwB/tFxMT06CtZ8+eAJw9exb4bknM\n99u/r0ePHhiNRmffM2fO4HA46N279zXFGRoaire3d722wMBAAEpKSq7pM0REbgW6iVVERNqEq61x\ndzgcrRiJiIhrqYAXEZFrkpeX16Dt+PHjAHTr1g2Arl271mv/vhMnTlBbW+vsGxkZicFgIDc3t6VC\nFhG5JamAFxGRa7J9+3YOHTrk/NnhcDBv3jwARo4cCUBwcDCpqals2rSJY8eO1es7Z84cADIzM4Hv\nlr9kZGSQnZ3N9u3bG+xPs+oiIo3TGngRkXbu8OHDrFixotFtdYU5QHx8PA899BATJ07EbDazYcMG\ntm/fzujRo0lNTXX2e/HFF5k8eTITJ05kwoQJmM1mNm3axNatWxk1apTzCTQAv/nNbzh8+DBTp07l\nvvvuIzExkaqqKmw2G126dOH5559vuQMXEWmjVMCLiLRzq1atYtWqVY1uW7dunXPt+fDhw4mOjuad\nd97h5MmTBAcH88QTT/DEE0/UG5OUlMSiRYv405/+xAcffEBFRQXdunXjueee49FHH63Xt1u3bnz8\n8cf8+c9/Jjs7mxUrVuDv7098fDzjxo1rmQMWEWnjDA59RykiIldx7tw5RowYwVNPPcXTTz/t6nBE\nRNo9rYEXEREREWlDVMCLiIiIiLQhKuBFRERERNoQrYEXEREREWlDNAMvIiIiItKGqIAXEREREWlD\nVMCLiIiIiLQhKuBFRERERNoQFfAiIiIiIm2ICngRERERkTbk/wGEmtgaIm2W4gAAAABJRU5ErkJg\ngg==\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ4uQ6n_GHPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = testdf['clean_text']\n",
        "labels = testdf['sentiment']\n",
        "labels = le.transform(labels)\n",
        "# Report the number of sentences.\n",
        "\n",
        "# Create sentence and label lists\n",
        "# sentences = df.sentence.values\n",
        "# labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKXhHukvGOc4",
        "colab_type": "code",
        "outputId": "277b460a-c18d-4a41-fc15-ee7008f59568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 3,400 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K3-WNrjGQJ3",
        "colab_type": "code",
        "outputId": "7a7aa73f-82e7-4e0b-a071-c82e8e46a012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doAjXriWGRqv",
        "colab_type": "code",
        "outputId": "370ecc18-3477-4fc7-fb6f-cbe1774d968a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "matthews_set"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3931596882994797,\n",
              " 0.49563890826286494,\n",
              " 0.29682219013261923,\n",
              " 0.45938944960956696,\n",
              " 0.47990688995165065,\n",
              " 0.4679899798811505,\n",
              " 0.6291909571561632,\n",
              " 0.29731874789914864,\n",
              " 0.43302545296582723,\n",
              " 0.48382562208766616,\n",
              " 0.6375087874016577,\n",
              " 0.4414935939547401,\n",
              " 0.27114461262033085,\n",
              " 0.337944722324887,\n",
              " 0.4838709677419355,\n",
              " 0.48588573510054384,\n",
              " 0.3731117824773414,\n",
              " 0.38310752476601245,\n",
              " 0.41853933527826886,\n",
              " 0.5172938179593085,\n",
              " 0.6114890620314475,\n",
              " 0.3840518241806561,\n",
              " 0.5102383303206351,\n",
              " 0.5031482208955829,\n",
              " 0.4616189941836674,\n",
              " 0.5796842079430553,\n",
              " 0.6329831862389969,\n",
              " 0.6205523057021035,\n",
              " 0.5623100303951368,\n",
              " 0.3236872161474422,\n",
              " 0.48672566371681414,\n",
              " 0.39054792812130745,\n",
              " 0.40236862491468006,\n",
              " 0.345251085785819,\n",
              " 0.3721672219030971,\n",
              " 0.3921573088156033,\n",
              " 0.3378926905477037,\n",
              " 0.5238899335193017,\n",
              " 0.4573476059357388,\n",
              " 0.34167931016926417,\n",
              " 0.24701595247415287,\n",
              " 0.4380888936555099,\n",
              " 0.5297994485700921,\n",
              " 0.23184479546637446,\n",
              " 0.5159480830242561,\n",
              " 0.4827404562314991,\n",
              " 0.486609297983877,\n",
              " 0.45037481853869266,\n",
              " 0.1684582308505468,\n",
              " 0.5449492609130662,\n",
              " 0.5227445000873798,\n",
              " 0.5197566329736368,\n",
              " 0.5315717919058291,\n",
              " 0.48214499249778636,\n",
              " 0.33733748091818316,\n",
              " 0.6246400804018807,\n",
              " 0.20426700673502704,\n",
              " 0.4217180976033088,\n",
              " 0.4146142683991519,\n",
              " 0.33548626922909625,\n",
              " 0.3863302927506364,\n",
              " 0.38018000948427905,\n",
              " 0.23802501893915326,\n",
              " 0.5342853505585049,\n",
              " 0.5868921130416285,\n",
              " 0.3995965707495983,\n",
              " 0.4984871372281065,\n",
              " 0.5799759360284583,\n",
              " 0.2744106499742259,\n",
              " 0.47654590699544463,\n",
              " 0.21473352547735275,\n",
              " 0.4292632827107269,\n",
              " 0.3196528469126911,\n",
              " 0.6210398168589427,\n",
              " 0.4277593563577607,\n",
              " 0.4940826318125578,\n",
              " 0.3934217775231159,\n",
              " 0.4967845659163987,\n",
              " 0.5463562949620565,\n",
              " 0.33544178429994304,\n",
              " 0.6276116271747901,\n",
              " 0.48600936360283264,\n",
              " 0.3662271808287441,\n",
              " 0.44042282374675445,\n",
              " 0.4823008849557522,\n",
              " 0.532258064516129,\n",
              " 0.4743289004888588,\n",
              " 0.24520181662864815,\n",
              " 0.24518451837010066,\n",
              " 0.2527550241627901,\n",
              " 0.34956360572301926,\n",
              " 0.4431435483460417,\n",
              " 0.6992204017840304,\n",
              " 0.550053820548846,\n",
              " 0.4852092241618201,\n",
              " 0.5676056344468035,\n",
              " 0.14307813057710717,\n",
              " 0.28771456116935107,\n",
              " 0.5122419969659783,\n",
              " 0.5059791665613768,\n",
              " 0.6229847204962421,\n",
              " 0.5997262863350047,\n",
              " -0.03087140334613169,\n",
              " 0.6250027680526861,\n",
              " 0.49262295478937645,\n",
              " 0.6293957847068912,\n",
              " 0.5642880936468347]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUURL9eNGUIS",
        "colab_type": "code",
        "outputId": "96bf4d86-33e2-40ac-9454-90a2cecad427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.442\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rejd9lHUGZVi",
        "colab_type": "code",
        "outputId": "c28df541-23a2-489f-bb96-4e557b331a1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/vocab.txt',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOrTUC3JGZuo",
        "colab_type": "code",
        "outputId": "1a765745-90a3-477f-de6c-58592539a991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(flat_predictions, flat_true_labels, average='macro')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6320195662439589"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_3PEYbgGbc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5doLGaOG66J",
        "colab_type": "text"
      },
      "source": [
        "# Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX_QSsfKG8eF",
        "colab_type": "code",
        "outputId": "a104ec92-96f7-40cc-acd1-b745d0259b59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/vocab.txt',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty-QIJMKHB29",
        "colab_type": "code",
        "outputId": "b6fa9e85-c2a0-4235-f0e0-f31522013cd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!cp -r ./model_save/ \"./drive/My Drive/Hinglish/HinglishBERT/"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: line 0: unexpected EOF while looking for matching `\"'\n",
            "/bin/bash: -c: line 1: syntax error: unexpected end of file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76lFSFVgHMhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Load a trained model and vocabulary that you have fine-tuned\n",
        "# model = model_class.from_pretrained(output_dir)\n",
        "# tokenizer = tokenizer_class.from_pretrained(output_dir)\n",
        "\n",
        "# # Copy the model to the GPU.\n",
        "# model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVE-y1r03Wrl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "df17eadf-a694-4585-a36b-c974eb0870cb"
      },
      "source": [
        "sentences = validdf['clean_text']\n",
        "labels = validdf['sentiment']\n",
        "# Report the number of sentences.\n",
        "\n",
        "# Create sentence and label lists\n",
        "# sentences = df.sentence.values\n",
        "# labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "\n",
        "# Prediction on valid set\n",
        "\n",
        "print('Predicting labels for {:,} valid sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')\n",
        "\n",
        "\n",
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 3,000 valid sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIZQKyvSBMPf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38e388c0-353c-4a66-e250-287cb4237b88"
      },
      "source": [
        "len(flat_predictions.tolist())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gsvaRhMHNCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = le.inverse_transform(flat_predictions.tolist())\n",
        "with open('answer.txt', 'w') as f:\n",
        "    for i in range(len(output.tolist())):\n",
        "        f.write(f\"{validdf.loc[i]['uid']},{output[i]}\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwTbKCnFHgtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp answer.txt drive/My\\ Drive/Hinglish/"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}