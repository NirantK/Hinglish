{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RoBERTa.ipynb",
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm",
      "mount_file_id": "1Xtd0C11wkcMSpTd_6bm5HXQTHDy-UDXQ",
      "authorship_tag": "ABX9TyNiPKeIVWLOTf/xVjAsTXPV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NirantK/Hinglish/blob/RoBERTa/RoBERTa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liadde_Nq2t4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install sentencepiece\n",
        "# !pip install cleantext\n",
        "# import nltk\n",
        "# nltk.download('stopwords')\n",
        "# !pip install tqdm --upgrade --force"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhwloxTFju5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install fairseq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HcaP8M6g9k3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !git clone https://github.com/pytorch/fairseq.git\n",
        "# %cd ..\n",
        "# !ls\n",
        "# !pip install --editable ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uSdzqqsVMRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp drive/My\\ Drive/Hinglish/big/lm_data.txt hinglish/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-3umcKorFd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "import sentencepiece as spm\n",
        "from pathlib import Path\n",
        "import cleantext\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import gdown\n",
        "\n",
        "tqdm.pandas()\n",
        "data_folder = Path(\"drive/My Drive/Hinglish/big\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzVJDm_7pXpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "data = open('hinglish/lm_data.txt').readlines()\n",
        "train, test = train_test_split(data, test_size=0.2, random_state=1)\n",
        "train, valid = train_test_split(train, test_size=0.2, random_state=1)\n",
        "len(train), len(test), len(valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdSPnnEnqENn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def clean(df, col):\n",
        "    \"\"\"Cleaning Twitter data\n",
        "    \n",
        "    Arguments:\n",
        "        df {[pandas dataframe]} -- Dataset that needs to be cleaned\n",
        "        col {[string]} -- column in which text is present\n",
        "    \n",
        "    Returns:\n",
        "        [pandas dataframe] -- Datframe with a \"clean_text\" column\n",
        "    \"\"\"\n",
        "    df[\"clean_text\"] = df[col]\n",
        "    df[\"clean_text\"] = (\n",
        "        (df[\"clean_text\"])\n",
        "        .progress_apply(lambda text: re.sub(r\"RT\\s@\\w+:\", \"\", text))  # Removes RTS\n",
        "        .progress_apply(\n",
        "            lambda text: re.sub(r\"@\\w+ ?\", \"\", text)\n",
        "        )  # Replaces @ with mention\n",
        "        .progress_apply(lambda text: re.sub(r\"RT\", \"\", text))  # Replaces @ with mention\n",
        "        .progress_apply(\n",
        "            lambda text: re.sub(r\"#\\w+ ?\", \"\", text)\n",
        "        )  # Replaces # with hastag\n",
        "        .progress_apply(lambda text: re.sub(r\"http\\S+\", \"\", text))  # Removes URL\n",
        "    )\n",
        "    df[\"clean_text\"] = df[\"clean_text\"].progress_apply(\n",
        "        lambda x: cleantext.clean(x, all=True)\n",
        "    )\n",
        "    return df\n",
        "\n",
        "\n",
        "toy = pd.DataFrame([\"RT @meghana https://something hello\"], columns=[\"text\"])\n",
        "clean(toy, \"text\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB3lwgYSyaMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(data):\n",
        "    df = clean(pd.DataFrame(data, columns=[\"text\"]), \"text\")\n",
        "    return list(df['clean_text'])\n",
        "    \n",
        "train = clean_text(train)\n",
        "test = clean_text(test)\n",
        "valid = clean_text(valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsstbRAgyuaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train[:5], test[:5], valid[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUMDFulZqPUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(f'hinglish/lm_data.valid.txt', 'w') as f:\n",
        "    for item in valid:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M05Ok1FF8yqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp hinglish/lm_data.train.txt  ../drive/My\\ Drive/Hinglish/ \n",
        "!cp hinglish/lm_data.test.txt  ../drive/My\\ Drive/Hinglish/ \n",
        "!cp hinglish/lm_data.valid.txt  ../drive/My\\ Drive/Hinglish/ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcp1fd39XJY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import pdb \n",
        "# !mkdir -p gpt2_bpe\n",
        "# !wget -O gpt2_bpe/encoder.json https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json\n",
        "# !wget -O gpt2_bpe/vocab.bpe https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe\n",
        "!for SPLIT in train valid test; do python -m examples.roberta.multiprocessing_bpe_encoder --encoder-json gpt2_bpe/encoder.json --vocab-bpe gpt2_bpe/vocab.bpe --inputs hinglish/lm_data.${SPLIT}.txt --outputs hinglish/lm_data.${SPLIT}.bpe --keep-empty --workers 60; done"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCuft697Xlrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget -O gpt2_bpe/dict.txt https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/dict.txt\n",
        "!fairseq-preprocess --only-source --srcdict gpt2_bpe/dict.txt --trainpref hinglish/lm_data.train.bpe --validpref hinglish/lm_data.valid.bpe --testpref hinglish/lm_data.test.bpe --destdir data-bin/hinglish --workers 60"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COFsR9W_Xw7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!fairseq-train  data-bin/hinglish --task masked_lm --criterion masked_lm --arch roberta_base --sample-break-mode complete --tokens-per-sample 512 --optimizer adam --adam-betas '(0.9,0.98)' --adam-eps 1e-6 --clip-norm 0.0 --lr-scheduler polynomial_decay --lr 0.0005 --warmup-updates 10000 --total-num-update 125000 --dropout 0.1 --attention-dropout 0.1 --weight-decay 0.01 --max-sentences 16 --update-freq 16 --max-update 125000 --log-format simple --log-interval 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjkIth8eir8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fairseq.models.roberta import RobertaModel\n",
        "import torch\n",
        "roberta = RobertaModel.from_pretrained('checkpoints', 'checkpoint_best.pt', '/content/fairseq/data-bin/hinglish')\n",
        "assert isinstance(roberta.model, torch.nn.Module)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arxYt8_nX72g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roberta.eval()  # disable dropout for evaluation\n",
        "\n",
        "# Encode a pair of sentences and make a prediction\n",
        "tokens = roberta.encode('Roberta is a heavily optimized version of BERT.', 'Roberta is not very optimized.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKfR77dJYD_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_tajt87uPdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /content/fairseq/checkpoints"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlSNC2Z0W5eV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/fairseq/data-bin/hinglish/dict.txt /content/fairseq/checkpoints"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDII5ZtMXH10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r checkpoints ../drive/My\\ Drive/Hinglish/\n",
        "!cp -r data-bin ../drive/My\\ Drive/Hinglish/\n",
        "!cp -r hinglish ../drive/My\\ Drive/Hinglish/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KUBZRumY-51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp ../drive/My\\ Drive/Hinglish/interim/train.json hinglish \n",
        "!cp ../drive/My\\ Drive/Hinglish/interim/test.json hinglish "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuHGv6U7ZrzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_json(\"hinglish/train.json\")\n",
        "train_df = clean(train_df, 'text')\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c4Bod-IaAlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(train_df['sentiment'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32pRN1IqaZVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le.classes_, le.inverse_transform([0, 1, 2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc-W430iadLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(f'hinglish/train.labels', 'w') as f:\n",
        "    for item in list(le.transform(train_df['sentiment'])):\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E10HPTPabKW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(f'hinglish/train.input0', 'w') as f:\n",
        "    for item in list(train_df['clean_text']):\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-q991r2a7bo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_json(\"hinglish/test.json\")\n",
        "test_df = clean(test_df, 'text')\n",
        "test_df.head()\n",
        "\n",
        "with open(f'hinglish/test.labels', 'w') as f:\n",
        "    for item in list(le.transform(test_df['sentiment'])):\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_icQQEBCbR2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(f'hinglish/test.input0', 'w') as f:\n",
        "    for item in list(test_df['clean_text']):\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH5UBDQPba0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download encoder.json and vocab.bpe\n",
        "# !wget -N 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json'\n",
        "# !wget -N 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'\n",
        "\n",
        "!python -m examples.roberta.multiprocessing_bpe_encoder --encoder-json encoder.json --vocab-bpe vocab.bpe --inputs \"hinglish/train.input0\" --outputs \"hinglish/train.input0.bpe\" --workers 60 --keep-empty"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba7TSKitdiWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python -m examples.roberta.multiprocessing_bpe_encoder --encoder-json encoder.json --vocab-bpe vocab.bpe --inputs \"hinglish/test.input0\" --outputs \"hinglish/test.input0.bpe\" --workers 60 --keep-empty"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO_u9Bp2bx7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download fairseq dictionary.\n",
        "!wget -N 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/dict.txt'  \n",
        "\n",
        "!fairseq-preprocess --only-source --trainpref \"hinglish/train.input0.bpe\" --validpref \"hinglish/test.input0.bpe\" --destdir \"hinglish-class/input0\" --workers 60 --srcdict dict.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvRh_Dnzdm2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!fairseq-preprocess --only-source --trainpref \"hinglish/train.labels\" --validpref \"hinglish/test.labels\" --destdir \"hinglish-class/label\" --workers 60"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvKWXGHdeF99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python train.py hinglish-class/ --restore-file checkpoints/checkpoint_best.pt --max-positions 512 --max-sentences 8 --max-tokens 4400 --task sentence_prediction --reset-optimizer --reset-dataloader --reset-meters --required-batch-size-multiple 1 --init-token 0 --separator-token 2 --criterion sentence_prediction --classification-head-name hinglish_head --num-classes 3 --dropout 0.1 --attention-dropout 0.1 --weight-decay 0.1 --optimizer adam --adam-betas \"(0.9, 0.98)\" --adam-eps 1e-06 --clip-norm 0.0 --lr-scheduler polynomial_decay --lr 1e-05 --total-num-update 7812 --warmup-updates 469 --fp16 --fp16-init-scale 4 --threshold-loss-scale 1 --fp16-scale-window 128 --max-epoch 10 --best-checkpoint-metric accuracy --maximize-best-checkpoint-metric --truncate-sequence --find-unused-parameters --update-freq 4 --arch roberta_base"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}