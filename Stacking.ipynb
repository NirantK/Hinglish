{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stacking.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/NirantK/Hinglish/blob/stack/Stacking.ipynb",
      "authorship_tag": "ABX9TyOlcvCXusRpZWHuWygk9euR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NirantK/Hinglish/blob/stack/Stacking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMcdkUPQuMIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import  f1_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier, Perceptron\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.multiclass import OutputCodeClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMUqYZ1AuOV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_BERT_64= pd.read_csv(\"/content/drive/My Drive/BERT_valid64.csv\")\n",
        "df_BERT_649= pd.read_csv(\"/content/drive/My Drive/BERT_valid64_9.csv\")\n",
        "df_BERT_65= pd.read_csv(\"/content/drive/My Drive/BERT_valid65.csv\")\n",
        "df_DistilBERT_64= pd.read_csv(\"/content/drive/My Drive/DistilBERT_valid64_1.csv\")\n",
        "df_DistilBERT_65= pd.read_csv(\"/content/drive/My Drive/DistilBERT_valid65.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8LziL-RKRDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = pd.read_csv(\"test_labels_hinglish.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qR51POKcvIOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(df_BERT_64[\"actual\"])\n",
        "y = le.transform(df_BERT_64[\"actual\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHn07Co_vd_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame()\n",
        "df[\"BERT_64_negative\"] = df_BERT_64[\"proba_negative\"]\n",
        "df[\"BERT_64_neutral\"] = df_BERT_64[\"proba_neutral\"]\n",
        "df[\"BERT_64_positive\"] = df_BERT_64[\"proba_positive\"]\n",
        "# df[\"BERT_64_sentiment\"] = le.transform(df_BERT_64[\"Sentiment\"])\n",
        "\n",
        "\n",
        "df[\"BERT_649_negative\"] = df_BERT_649[\"proba_negative\"]\n",
        "df[\"BERT_649_neutral\"] = df_BERT_649[\"proba_neutral\"]\n",
        "df[\"BERT_649_positive\"] = df_BERT_649[\"proba_positive\"]\n",
        "# df[\"BERT_649_sentiment\"] = le.transform(df_BERT_649[\"Sentiment\"])\n",
        "\n",
        "df[\"BERT_65_negative\"] = df_BERT_65[\"proba_negative\"]\n",
        "df[\"BERT_65_neutral\"] = df_BERT_65[\"proba_neutral\"]\n",
        "df[\"BERT_65_positive\"] = df_BERT_65[\"proba_positive\"]\n",
        "# df[\"BERT_65_sentiment\"] = le.transform(df_BERT_65[\"Sentiment\"])\n",
        "\n",
        "# df[\"DistilBERT_64_negative\"] = df_DistilBERT_64[\"proba_negative\"]\n",
        "# df[\"DistilBERT_64_neutral\"] = df_DistilBERT_64[\"proba_neutral\"]\n",
        "# df[\"DistilBERT_64_positive\"] = df_DistilBERT_64[\"proba_positive\"]\n",
        "# df[\"DistilBERT_64_sentiment\"] = le.transform(df_DistilBERT_64[\"Sentiment\"])\n",
        "\n",
        "df[\"DistilBERT_65_negative\"] = df_DistilBERT_65[\"proba_negative\"]\n",
        "df[\"DistilBERT_65_neutral\"] = df_DistilBERT_65[\"proba_neutral\"]\n",
        "df[\"DistilBERT_65_positive\"] = df_DistilBERT_65[\"proba_positive\"]\n",
        "# df[\"DistilBERT_64_sentiment\"] = le.transform(df_DistilBERT_64[\"Sentiment\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XgnC5rtv6X-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "72bbb88c-5ff4-4cc6-ca44-cc99c05cad94"
      },
      "source": [
        "df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BERT_64_negative</th>\n",
              "      <th>BERT_64_neutral</th>\n",
              "      <th>BERT_64_positive</th>\n",
              "      <th>BERT_649_negative</th>\n",
              "      <th>BERT_649_neutral</th>\n",
              "      <th>BERT_649_positive</th>\n",
              "      <th>BERT_65_negative</th>\n",
              "      <th>BERT_65_neutral</th>\n",
              "      <th>BERT_65_positive</th>\n",
              "      <th>DistilBERT_65_negative</th>\n",
              "      <th>DistilBERT_65_neutral</th>\n",
              "      <th>DistilBERT_65_positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.917023</td>\n",
              "      <td>0.848260</td>\n",
              "      <td>-0.051328</td>\n",
              "      <td>0.209021</td>\n",
              "      <td>0.352510</td>\n",
              "      <td>-0.177959</td>\n",
              "      <td>-0.294714</td>\n",
              "      <td>1.080749</td>\n",
              "      <td>-0.384878</td>\n",
              "      <td>-0.695175</td>\n",
              "      <td>1.094967</td>\n",
              "      <td>-0.102838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.819198</td>\n",
              "      <td>-0.355091</td>\n",
              "      <td>2.747333</td>\n",
              "      <td>-2.425666</td>\n",
              "      <td>-0.418156</td>\n",
              "      <td>2.154119</td>\n",
              "      <td>-2.254908</td>\n",
              "      <td>-0.240274</td>\n",
              "      <td>2.648540</td>\n",
              "      <td>-2.401496</td>\n",
              "      <td>-0.156448</td>\n",
              "      <td>2.381583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.718215</td>\n",
              "      <td>0.099927</td>\n",
              "      <td>-0.937183</td>\n",
              "      <td>1.488221</td>\n",
              "      <td>-0.056952</td>\n",
              "      <td>-1.003402</td>\n",
              "      <td>1.199084</td>\n",
              "      <td>0.062261</td>\n",
              "      <td>-0.928962</td>\n",
              "      <td>0.039550</td>\n",
              "      <td>0.890880</td>\n",
              "      <td>-0.715390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.274513</td>\n",
              "      <td>1.194077</td>\n",
              "      <td>-1.450490</td>\n",
              "      <td>-0.487120</td>\n",
              "      <td>1.090277</td>\n",
              "      <td>-0.464433</td>\n",
              "      <td>-0.684138</td>\n",
              "      <td>1.359785</td>\n",
              "      <td>-0.733373</td>\n",
              "      <td>-1.132596</td>\n",
              "      <td>1.956391</td>\n",
              "      <td>-0.537584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.021685</td>\n",
              "      <td>0.378019</td>\n",
              "      <td>-1.692840</td>\n",
              "      <td>0.090764</td>\n",
              "      <td>1.088896</td>\n",
              "      <td>-1.045575</td>\n",
              "      <td>1.926701</td>\n",
              "      <td>-0.365329</td>\n",
              "      <td>-1.640216</td>\n",
              "      <td>0.409683</td>\n",
              "      <td>1.072245</td>\n",
              "      <td>-1.329250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3395</th>\n",
              "      <td>0.926643</td>\n",
              "      <td>0.360316</td>\n",
              "      <td>-1.596923</td>\n",
              "      <td>0.649896</td>\n",
              "      <td>0.637028</td>\n",
              "      <td>-0.925685</td>\n",
              "      <td>1.940947</td>\n",
              "      <td>-0.373891</td>\n",
              "      <td>-1.447588</td>\n",
              "      <td>1.003608</td>\n",
              "      <td>0.185675</td>\n",
              "      <td>-0.828389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3396</th>\n",
              "      <td>1.203240</td>\n",
              "      <td>-0.541484</td>\n",
              "      <td>-0.769724</td>\n",
              "      <td>0.352287</td>\n",
              "      <td>0.630015</td>\n",
              "      <td>-0.651350</td>\n",
              "      <td>0.191140</td>\n",
              "      <td>0.480588</td>\n",
              "      <td>-0.406958</td>\n",
              "      <td>1.122909</td>\n",
              "      <td>0.121761</td>\n",
              "      <td>-0.816524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3397</th>\n",
              "      <td>1.340941</td>\n",
              "      <td>-0.047205</td>\n",
              "      <td>-1.771406</td>\n",
              "      <td>0.316862</td>\n",
              "      <td>0.951470</td>\n",
              "      <td>-1.014989</td>\n",
              "      <td>1.136088</td>\n",
              "      <td>0.163875</td>\n",
              "      <td>-1.510247</td>\n",
              "      <td>2.516004</td>\n",
              "      <td>-0.581253</td>\n",
              "      <td>-1.438948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3398</th>\n",
              "      <td>0.969914</td>\n",
              "      <td>-0.039714</td>\n",
              "      <td>-0.989335</td>\n",
              "      <td>1.773173</td>\n",
              "      <td>-0.186627</td>\n",
              "      <td>-1.019375</td>\n",
              "      <td>1.853034</td>\n",
              "      <td>-0.304274</td>\n",
              "      <td>-1.521759</td>\n",
              "      <td>1.919484</td>\n",
              "      <td>-0.148285</td>\n",
              "      <td>-1.214098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3399</th>\n",
              "      <td>-1.781864</td>\n",
              "      <td>-0.243541</td>\n",
              "      <td>2.616847</td>\n",
              "      <td>-2.192231</td>\n",
              "      <td>-0.510854</td>\n",
              "      <td>1.983877</td>\n",
              "      <td>-1.531184</td>\n",
              "      <td>-0.269304</td>\n",
              "      <td>1.825964</td>\n",
              "      <td>-2.084501</td>\n",
              "      <td>0.012508</td>\n",
              "      <td>2.104428</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3400 rows Ã— 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      BERT_64_negative  ...  DistilBERT_65_positive\n",
              "0            -0.917023  ...               -0.102838\n",
              "1            -1.819198  ...                2.381583\n",
              "2             0.718215  ...               -0.715390\n",
              "3             0.274513  ...               -0.537584\n",
              "4             1.021685  ...               -1.329250\n",
              "...                ...  ...                     ...\n",
              "3395          0.926643  ...               -0.828389\n",
              "3396          1.203240  ...               -0.816524\n",
              "3397          1.340941  ...               -1.438948\n",
              "3398          0.969914  ...               -1.214098\n",
              "3399         -1.781864  ...                2.104428\n",
              "\n",
              "[3400 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQGASQKRuELe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df, y, test_size=0.33, random_state=42)\n",
        "X = df "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyzBIWDWy_rL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clas = [\n",
        "#         KNeighborsClassifier(n_neighbors=15),\n",
        "#         LogisticRegression(C=0.1, multi_class=\"auto\"), \n",
        "#         SGDClassifier(average=True, max_iter=1000), \n",
        "#         LogisticRegression(solver='sag', tol=1e-1, C=1.0, multi_class=\"auto\"),\n",
        "#         LogisticRegression(solver='newton-cg', tol=1e-1, C=1.0, multi_class=\"auto\"),\n",
        "#         LogisticRegression(solver='liblinear', penalty='l2', multi_class=\"auto\"),\n",
        "#         LogisticRegression(solver='liblinear', C=10, penalty='l2', multi_class=\"auto\"),\n",
        "#         LogisticRegression(solver='liblinear', penalty='l1', multi_class=\"auto\"),\n",
        "#         LogisticRegression(solver='saga', multi_class=\"auto\"),\n",
        "#         ]\n",
        "\n",
        "# for m in clas:\n",
        "#     m.fit(X_train, y_train)\n",
        "#     predicted = m.predict(X_test)\n",
        "\n",
        "#     f1 = f1_score(y_test, predicted, average=\"macro\") \n",
        "#     print(f\"F1: {f1}\\n\\n{str(m)}\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlSem_-73-Lb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "de4e7729-4d8b-44c4-e535-56a6c1173ab8"
      },
      "source": [
        "m = LogisticRegression(C =10, solver='liblinear', penalty='l2', multi_class=\"auto\")\n",
        "m.fit(X_train, y_train)\n",
        "predicted = m.predict(X_test)\n",
        "f1 = f1_score(y_test, predicted, average=\"macro\") \n",
        "print(f\"F1: {f1}\\n\\n{str(m)}\\n\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1: 0.6700513538748835\n",
            "\n",
            "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLbxnRg5HmhS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "9b1fa520-467b-4ef3-d548-5e995a164157"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "pipe = Pipeline([('classifier' , LogisticRegression())])\n",
        "\n",
        "# Create param grid.\n",
        "\n",
        "param_grid = [\n",
        "    {'classifier' : [LogisticRegression()],\n",
        "     'classifier__penalty' : ['l1', 'l2'],\n",
        "    'classifier__C' : np.logspace(-40, 40, 20),\n",
        "    'classifier__solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']},\n",
        "]\n",
        "\n",
        "# Create grid search object\n",
        "\n",
        "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1)\n",
        "\n",
        "# Fit on data\n",
        "\n",
        "best_clf = clf.fit(X_train, y_train)\n",
        "predicted = best_clf.predict(X_test)\n",
        "f1 = f1_score(y_test, predicted, average=\"macro\") \n",
        "print(f\"F1: {f1}\\n\\n{str(best_clf)}\\n\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 500 tasks      | elapsed:   15.6s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1: 0.6473093401320998\n",
            "\n",
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=Pipeline(memory=None,\n",
            "                                steps=[('classifier',\n",
            "                                        LogisticRegression(C=1.0,\n",
            "                                                           class_weight=None,\n",
            "                                                           dual=False,\n",
            "                                                           fit_intercept=True,\n",
            "                                                           intercept_scaling=1,\n",
            "                                                           l1_ratio=None,\n",
            "                                                           max_iter=100,\n",
            "                                                           multi_class='auto',\n",
            "                                                           n_jobs=None,\n",
            "                                                           penalty='l2',\n",
            "                                                           random_state=None,\n",
            "                                                           solver='lbfgs',\n",
            "                                                           tol=0.0001,\n",
            "                                                           verbose=0,\n",
            "                                                           warm_start=False))],\n",
            "                                verbose=False),\n",
            "             iid='deprec...\n",
            "       4.83293024e-07, 7.84759970e-03, 1.27427499e+02, 2.06913808e+06,\n",
            "       3.35981829e+10, 5.45559478e+14, 8.85866790e+18, 1.43844989e+23,\n",
            "       2.33572147e+27, 3.79269019e+31, 6.15848211e+35, 1.00000000e+40]),\n",
            "                          'classifier__penalty': ['l1', 'l2'],\n",
            "                          'classifier__solver': ['newton-cg', 'lbfgs',\n",
            "                                                 'liblinear', 'sag', 'saga']}],\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=None, verbose=True)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:   19.4s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhZQsCKaYTQj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "bf24a2c4-3364-481a-bd87-ffa88763b7c4"
      },
      "source": [
        "m = LogisticRegression(C =20, solver='liblinear', penalty='l2', multi_class=\"auto\")\n",
        "m.fit(X, y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=20, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDL7HKP7YLsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_BERT_64= pd.read_csv(\"/content/drive/My Drive/BERT_test64.csv\")\n",
        "df_BERT_649= pd.read_csv(\"/content/drive/My Drive/BERT_test64_9.csv\")\n",
        "df_BERT_65= pd.read_csv(\"/content/drive/My Drive/BERT_test65.csv\")\n",
        "df_DistilBERT_64= pd.read_csv(\"/content/drive/My Drive/DistilBERT_test64_1.csv\")\n",
        "df_DistilBERT_65= pd.read_csv(\"/content/drive/My Drive/DistilBERT_test65.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWanAh0AYe7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame()\n",
        "df[\"BERT_64_negative\"] = df_BERT_64[\"proba_negative\"]\n",
        "df[\"BERT_64_neutral\"] = df_BERT_64[\"proba_neutral\"]\n",
        "df[\"BERT_64_positive\"] = df_BERT_64[\"proba_positive\"]\n",
        "# df[\"BERT_64_sentiment\"] = le.transform(df_BERT_64[\"Sentiment\"])\n",
        "\n",
        "\n",
        "df[\"BERT_649_negative\"] = df_BERT_649[\"proba_negative\"]\n",
        "df[\"BERT_649_neutral\"] = df_BERT_649[\"proba_neutral\"]\n",
        "df[\"BERT_649_positive\"] = df_BERT_649[\"proba_positive\"]\n",
        "# df[\"BERT_649_sentiment\"] = le.transform(df_BERT_649[\"Sentiment\"])\n",
        "\n",
        "df[\"BERT_65_negative\"] = df_BERT_65[\"proba_negative\"]\n",
        "df[\"BERT_65_neutral\"] = df_BERT_65[\"proba_neutral\"]\n",
        "df[\"BERT_65_positive\"] = df_BERT_65[\"proba_positive\"]\n",
        "# df[\"BERT_65_sentiment\"] = le.transform(df_BERT_65[\"Sentiment\"])\n",
        "\n",
        "# df[\"DistilBERT_64_negative\"] = df_DistilBERT_64[\"proba_negative\"]\n",
        "# df[\"DistilBERT_64_neutral\"] = df_DistilBERT_64[\"proba_neutral\"]\n",
        "# df[\"DistilBERT_64_positive\"] = df_DistilBERT_64[\"proba_positive\"]\n",
        "# df[\"DistilBERT_64_sentiment\"] = le.transform(df_DistilBERT_64[\"Sentiment\"])\n",
        "\n",
        "df[\"DistilBERT_65_negative\"] = df_DistilBERT_65[\"proba_negative\"]\n",
        "df[\"DistilBERT_65_neutral\"] = df_DistilBERT_65[\"proba_neutral\"]\n",
        "df[\"DistilBERT_65_positive\"] = df_DistilBERT_65[\"proba_positive\"]\n",
        "# df[\"DistilBERT_64_sentiment\"] = le.transform(df_DistilBERT_64[\"Sentiment\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-61D11M6SXZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted = m.predict(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8cQ72b-Ykdp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "6bd36cdc-b98d-496d-d02d-c344748e69e6"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.countplot(predicted)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fec1c945400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hfo82IuYl4k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d58a6a36-6c26-4364-82d8-695a9ec75ca7"
      },
      "source": [
        "output = le.inverse_transform(predicted)\n",
        "output"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['neutral', 'negative', 'neutral', ..., 'positive', 'neutral',\n",
              "       'neutral'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNjQOBV3Y5EG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputdf = df_BERT_64\n",
        "outputdf[\"output\"] = output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmDKqTHTY8cZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# outputdf.to_csv(\"drive/My Drive/67.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec6EnaliO1XZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4aff7d77-e04c-49b8-c605-3ad4395345e0"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "precision_recall_fscore_support(outputdf[\"Sentiment\"], l[\"Sentiment\"][:-1], average=\"macro\"), accuracy_score(outputdf[\"Sentiment\"], l[\"Sentiment\"][:-1])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((0.6782804462871205, 0.6960534570406008, 0.6844081334326786, None),\n",
              " 0.6785595198399467)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu_DzodLO4Tv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}