{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/NirantK/Hinglish/blob/mergeall/misc/MajorityVoting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_output_path = Path(\"/content/drive/My Drive/HinglishNLP/PredOutput\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = pd.read_csv(\"test_labels_hinglish.txt\")\n",
    "ref = pd.read_csv(\"/content/drive/My Drive/BERT_valid64.csv\")\n",
    "\n",
    "DistilBert1 = pd.read_csv(pred_output_path / \"D1-test-full-output.csv\")\n",
    "DistilBert2 = pd.read_csv(pred_output_path / \"D2-test-full-output.csv\")\n",
    "DistilBert3 = pd.read_csv(pred_output_path / \"D3-test-full-output.csv\")\n",
    "Bert1 = pd.read_csv(pred_output_path / \"B1-test-full-output.csv\")\n",
    "Bert2 = pd.read_csv(pred_output_path / \"B2-test-full-output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(ref[\"actual\"])\n",
    "clfs = [DistilBert1, DistilBert2, DistilBert3, Bert1, Bert2]\n",
    "for df in clfs:\n",
    "    df[\"y\"] = le.transform(df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Majority Voting | the _how_?\n",
    "Modified version of code from [this blog](https://sebastianraschka.com/Articles/2014_ensemble_classifier.html) about Majority Voting.\n",
    "\n",
    "- `np.bincount(classes_[:,0])` -> returns bin-count for each prediction class for a given output. So if out of five classifiers one said positive[0] and one said neutral[1] and three said negative[2] the output would look like array([1, 1, 3])\n",
    "- `np.argmax` -> get the pred which has the max bin-count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_ = np.asarray([clf[\"y\"] for clf in clfs])\n",
    "maj = np.asarray(\n",
    "    [np.argmax(np.bincount(classes_[:, c])) for c in range(classes_.shape[1])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    precision_recall_fscore_support(maj, le.transform(ref[\"actual\"]), average=\"macro\")\n",
    ")\n",
    "print(accuracy_score(maj, le.transform(ref[\"actual\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DistilBert1_final = pd.read_csv(pred_output_path / \"D1-final_test-full-output.csv\")\n",
    "DistilBert2_final = pd.read_csv(pred_output_path / \"D2-final_test-full-output.csv\")\n",
    "DistilBert3_final = pd.read_csv(pred_output_path / \"D3-final_test-full-output.csv\")\n",
    "Bert1_final = pd.read_csv(pred_output_path / \"B1-final_test-full-output.csv\")\n",
    "Bert2_final = pd.read_csv(pred_output_path / \"B2-final_test-full-output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [\n",
    "    DistilBert1_final,\n",
    "    DistilBert2_final,\n",
    "    DistilBert3_final,\n",
    "    Bert1_final,\n",
    "    Bert2_final,\n",
    "]\n",
    "for df in clfs:\n",
    "    df[\"y\"] = le.transform(df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_ = np.asarray([clf[\"y\"] for clf in clfs])\n",
    "maj = np.asarray(\n",
    "    [np.argmax(np.bincount(classes_[:, c])) for c in range(classes_.shape[1])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    precision_recall_fscore_support(\n",
    "        maj, le.transform(l[\"Sentiment\"][:-1]), average=\"macro\"\n",
    "    )\n",
    ")\n",
    "print(accuracy_score(maj, le.transform(l[\"Sentiment\"][:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
